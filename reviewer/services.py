from __future__ import annotations
import asyncio
import io
import re
import time
import logging
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from typing import Iterable, List, Sequence, Tuple, Optional, Callable, Any
from django.conf import settings
from django.db import transaction
from docx import Document
from openai import OpenAI, AsyncOpenAI
from serpapi import GoogleSearch
from asgiref.sync import sync_to_async
from .models import DocumentChunk, FileUploadBatch, UploadedFile


logger = logging.getLogger(__name__)

DEFAULT_EMBEDDING_MODEL = "text-embedding-3-small"
DEFAULT_COMPLETION_MODEL = "gpt-4.1"
MAX_CHUNK_CHAR_LENGTH = 4000
# OpenAI embedding limits: 8191 tokens per text, batch up to ~2000 texts
# For large documents, process embeddings in smaller batches to avoid rate limits
EMBEDDING_BATCH_SIZE = 100  # Number of texts to embed at once (increased for speed)
EMBEDDING_RETRY_DELAY = 1  # Seconds to wait between retries (reduced)
MAX_EMBEDDING_RETRIES = 5  # Maximum retry attempts for rate limits
MAX_CONCURRENT_EMBEDDINGS = 5  # Maximum concurrent embedding API calls


@dataclass
class RetrievedChunk:
    chunk: DocumentChunk
    similarity: float


def _get_openai_client() -> OpenAI:
    api_key = settings.OPENAI_API_KEY
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY env var must be set before calling OpenAI APIs.")
    return OpenAI(api_key=api_key)


def _get_async_openai_client() -> AsyncOpenAI:
    """Get an async OpenAI client for concurrent operations."""
    api_key = settings.OPENAI_API_KEY
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY env var must be set before calling OpenAI APIs.")
    return AsyncOpenAI(api_key=api_key)


def _extract_text_segments(file_obj) -> List[str]:
    """
    Read a DOCX file-like object and return non-empty text segments.
    """
    document = Document(file_obj)
    segments = []
    for paragraph in document.paragraphs:
        text = paragraph.text.strip()
        if text:
            segments.append(text)
    return segments


def _batch_segments(segments: Sequence[str], max_chars: int = MAX_CHUNK_CHAR_LENGTH) -> List[str]:
    """
    Merge sequential segments into chunks that respect the max_chars limit.
    """
    batches: List[str] = []
    current: List[str] = []
    current_len = 0

    for segment in segments:
        if not segment:
            continue
        candidate_len = current_len + len(segment) + (1 if current else 0)
        if candidate_len > max_chars and current:
            batches.append("\n".join(current))
            current = [segment]
            current_len = len(segment)
        else:
            current.append(segment)
            current_len = candidate_len

    if current:
        batches.append("\n".join(current))

    return batches


def _embed_texts(texts: Sequence[str], *, model: str = DEFAULT_EMBEDDING_MODEL) -> List[List[float]]:
    client = _get_openai_client()
    response = client.embeddings.create(model=model, input=list(texts))
    return [item.embedding for item in response.data]


def _embed_texts_chunked(
    texts: Sequence[str],
    *,
    model: str = DEFAULT_EMBEDDING_MODEL,
    batch_size: int = EMBEDDING_BATCH_SIZE,
    progress_callback: Optional[Callable[[int, int], None]] = None,
) -> List[List[float]]:
    """
    Embed texts in smaller batches to handle large documents and avoid rate limits.

    Args:
        texts: List of text segments to embed
        model: OpenAI embedding model to use
        batch_size: Number of texts to embed per API call
        progress_callback: Optional callback(processed, total) for progress tracking

    Returns:
        List of embedding vectors in the same order as input texts
    """
    if not texts:
        return []

    client = _get_openai_client()
    all_embeddings: List[List[float]] = []
    total_texts = len(texts)

    for i in range(0, total_texts, batch_size):
        batch = texts[i:i + batch_size]

        # Retry logic for rate limits
        for attempt in range(MAX_EMBEDDING_RETRIES):
            try:
                response = client.embeddings.create(model=model, input=list(batch))
                batch_embeddings = [item.embedding for item in response.data]
                all_embeddings.extend(batch_embeddings)

                if progress_callback:
                    progress_callback(min(i + batch_size, total_texts), total_texts)

                break  # Success, exit retry loop

            except Exception as e:
                error_str = str(e).lower()
                if "rate" in error_str or "limit" in error_str or "429" in error_str:
                    if attempt < MAX_EMBEDDING_RETRIES - 1:
                        wait_time = EMBEDDING_RETRY_DELAY * (attempt + 1)
                        logger.warning(f"Rate limit hit, waiting {wait_time}s before retry...")
                        time.sleep(wait_time)
                    else:
                        raise RuntimeError(f"Rate limit exceeded after {MAX_EMBEDDING_RETRIES} retries: {e}")
                else:
                    raise RuntimeError(f"Embedding API error: {e}")

        # Small delay between batches to avoid rate limits
        if i + batch_size < total_texts:
            time.sleep(0.1)

    return all_embeddings


def ingest_docx(
    *,
    file_obj,
    document_type: DocumentChunk.DocumentType,
    title: str | None = None,
    replace_existing: bool = False,
    use_chunked_embedding: bool = True,
    progress_callback: Optional[Callable[[int, int], None]] = None,
) -> List[DocumentChunk]:
    """
    Parse, chunk, embed, and persist DOCX content for the provided document type.

    Args:
        file_obj: File-like object containing the DOCX document
        document_type: Type of document (guideline or example)
        title: Optional title override
        replace_existing: Whether to replace existing documents with same title
        use_chunked_embedding: Use chunked embedding for large documents (default True)
        progress_callback: Optional callback(processed, total) for progress tracking

    Returns:
        List of created DocumentChunk objects
    """
    source_name = getattr(file_obj, "name", "") or ""
    file_obj.seek(0)
    segments = _extract_text_segments(file_obj)
    if not segments:
        raise ValueError("ูู ูุชู ุงูุนุซูุฑ ุนูู ูุต ุฏุงุฎู ุงูููู ุงููุฑููุน.")

    # Determine the final title
    final_title = title or source_name or document_type

    # Check if a document with this title already exists
    existing_chunks = DocumentChunk.objects.filter(
        document_type=document_type,
        title=final_title
    ).exists()

    if existing_chunks and not replace_existing:
        raise ValueError(f"ููุฌุฏ ูุณุชูุฏ ุจููุณ ุงูุนููุงู '{final_title}' ุจุงููุนู. ุงูุฑุฌุงุก ุงุฎุชูุงุฑ ุนููุงู ุขุฎุฑ ุฃู ุญุฐู ุงููุณุชูุฏ ุงูููุฌูุฏ ุฃููุงู.")

    batches = _batch_segments(segments)

    # Use chunked embedding for large documents (> 10 batches)
    if use_chunked_embedding and len(batches) > 10:
        embeddings = _embed_texts_chunked(batches, progress_callback=progress_callback)
    else:
        embeddings = _embed_texts(batches)

    if len(batches) != len(embeddings):
        raise RuntimeError("Embedding count mismatch while processing DOCX.")

    with transaction.atomic():
        if replace_existing:
            DocumentChunk.objects.filter(document_type=document_type, title=final_title).delete()

        created_chunks: List[DocumentChunk] = []
        for idx, (text, embedding) in enumerate(zip(batches, embeddings)):
            chunk = DocumentChunk.objects.create(
                document_type=document_type,
                title=final_title,
                source_name=source_name,
                order=idx,
                text=text,
                embedding=embedding,
                metadata={"segment_count": len(text.splitlines())},
            )
            created_chunks.append(chunk)

    return created_chunks


def ingest_multiple_docx(
    *,
    files: List[Tuple],  # List of (file_obj, optional_title) tuples
    document_type: DocumentChunk.DocumentType,
    replace_existing: bool = False,
) -> FileUploadBatch:
    """
    Process multiple DOCX files in a single batch operation.

    This function handles large documents efficiently by:
    1. Processing files sequentially to manage memory
    2. Using chunked embeddings to handle OpenAI rate limits
    3. Tracking progress at the file and batch level

    Args:
        files: List of (file_object, optional_title) tuples
        document_type: Type of documents (guideline or example)
        replace_existing: Whether to replace existing documents with same titles

    Returns:
        FileUploadBatch object with processing results
    """
    # Create batch record
    batch = FileUploadBatch.objects.create(
        document_type=document_type,
        status=FileUploadBatch.Status.PROCESSING,
        total_files=len(files),
    )

    # Create file records
    file_records: List[UploadedFile] = []
    for file_obj, title in files:
        filename = getattr(file_obj, "name", "") or f"file_{len(file_records)}.docx"
        file_size = 0
        try:
            file_obj.seek(0, 2)  # Seek to end
            file_size = file_obj.tell()
            file_obj.seek(0)  # Reset to beginning
        except Exception:
            pass

        file_record = UploadedFile.objects.create(
            batch=batch,
            filename=filename,
            title=title or "",
            file_size=file_size,
            status=UploadedFile.Status.PENDING,
        )
        file_records.append(file_record)

    total_chunks = 0
    processed = 0
    errors = []

    # Process each file
    for idx, ((file_obj, title), file_record) in enumerate(zip(files, file_records)):
        try:
            file_record.status = UploadedFile.Status.PROCESSING
            file_record.save()

            # Use title from parameter or from file record
            use_title = title or file_record.title or None

            chunks = ingest_docx(
                file_obj=file_obj,
                document_type=document_type,
                title=use_title,
                replace_existing=replace_existing,
                use_chunked_embedding=True,
            )

            file_record.status = UploadedFile.Status.COMPLETED
            file_record.chunks_created = len(chunks)
            file_record.save()

            total_chunks += len(chunks)
            processed += 1

        except Exception as e:
            error_msg = str(e)
            file_record.status = UploadedFile.Status.FAILED
            file_record.error_message = error_msg
            file_record.save()
            errors.append(f"{file_record.filename}: {error_msg}")
            logger.error(f"Error processing {file_record.filename}: {e}")

        # Update batch progress
        batch.processed_files = processed
        batch.total_chunks_created = total_chunks
        batch.save()

    # Update final batch status
    if errors:
        if processed == 0:
            batch.status = FileUploadBatch.Status.FAILED
        else:
            batch.status = FileUploadBatch.Status.COMPLETED  # Partial success
        batch.error_message = "\n".join(errors)
    else:
        batch.status = FileUploadBatch.Status.COMPLETED

    batch.save()
    return batch


def get_batch_status(batch_id: str) -> dict:
    """
    Get the current status of a batch upload.

    Args:
        batch_id: UUID of the batch

    Returns:
        Dictionary with batch status and file details
    """
    try:
        batch = FileUploadBatch.objects.get(id=batch_id)
    except FileUploadBatch.DoesNotExist:
        raise ValueError(f"Batch {batch_id} not found")

    files_info = []
    for f in batch.files.all():
        files_info.append({
            "filename": f.filename,
            "title": f.title,
            "status": f.status,
            "chunks_created": f.chunks_created,
            "file_size": f.file_size,
            "error_message": f.error_message,
        })

    progress = 0.0
    if batch.total_files > 0:
        progress = (batch.processed_files / batch.total_files) * 100

    return {
        "batch_id": str(batch.id),
        "document_type": batch.document_type,
        "status": batch.status,
        "total_files": batch.total_files,
        "processed_files": batch.processed_files,
        "total_chunks_created": batch.total_chunks_created,
        "progress_percentage": round(progress, 2),
        "error_message": batch.error_message,
        "files": files_info,
        "created_at": batch.created_at.isoformat(),
        "updated_at": batch.updated_at.isoformat(),
    }


# =============================================================================
# ASYNC PROCESSING FUNCTIONS FOR BIG DATA HANDLING
# =============================================================================

async def _async_embed_texts(
    texts: Sequence[str],
    *,
    model: str = DEFAULT_EMBEDDING_MODEL,
) -> List[List[float]]:
    """
    Asynchronously embed texts using OpenAI's async client.

    Args:
        texts: List of text segments to embed
        model: OpenAI embedding model to use

    Returns:
        List of embedding vectors in the same order as input texts
    """
    if not texts:
        return []

    client = _get_async_openai_client()
    response = await client.embeddings.create(model=model, input=list(texts))
    return [item.embedding for item in response.data]


async def _async_embed_texts_chunked(
    texts: Sequence[str],
    *,
    model: str = DEFAULT_EMBEDDING_MODEL,
    batch_size: int = EMBEDDING_BATCH_SIZE,
    max_concurrent: int = MAX_CONCURRENT_EMBEDDINGS,
) -> List[List[float]]:
    """
    Asynchronously embed texts in batches with concurrency control.

    This function handles large documents by:
    1. Breaking texts into smaller batches
    2. Processing batches concurrently (with limits to avoid rate limits)
    3. Implementing retry logic for rate limit errors

    Args:
        texts: List of text segments to embed
        model: OpenAI embedding model to use
        batch_size: Number of texts per batch
        max_concurrent: Maximum concurrent API calls

    Returns:
        List of embedding vectors in the same order as input texts
    """
    if not texts:
        return []

    client = _get_async_openai_client()
    all_embeddings: List[Optional[List[float]]] = [None] * len(texts)
    total_texts = len(texts)

    # Create batches with their indices
    batches = []
    for i in range(0, total_texts, batch_size):
        batch_texts = texts[i:i + batch_size]
        batch_indices = list(range(i, min(i + batch_size, total_texts)))
        batches.append((batch_indices, batch_texts))

    semaphore = asyncio.Semaphore(max_concurrent)

    async def process_batch(batch_indices: List[int], batch_texts: List[str]) -> None:
        async with semaphore:
            for attempt in range(MAX_EMBEDDING_RETRIES):
                try:
                    response = await client.embeddings.create(
                        model=model,
                        input=list(batch_texts)
                    )
                    for idx, item in zip(batch_indices, response.data):
                        all_embeddings[idx] = item.embedding
                    return
                except Exception as e:
                    error_str = str(e).lower()
                    if "rate" in error_str or "limit" in error_str or "429" in error_str:
                        if attempt < MAX_EMBEDDING_RETRIES - 1:
                            wait_time = EMBEDDING_RETRY_DELAY * (attempt + 1)
                            logger.warning(f"Rate limit hit, waiting {wait_time}s before retry...")
                            await asyncio.sleep(wait_time)
                        else:
                            raise RuntimeError(f"Rate limit exceeded after {MAX_EMBEDDING_RETRIES} retries: {e}")
                    else:
                        raise RuntimeError(f"Embedding API error: {e}")

    # Process all batches concurrently
    await asyncio.gather(*[
        process_batch(indices, texts_batch)
        for indices, texts_batch in batches
    ])

    return all_embeddings


async def async_ingest_docx(
    *,
    file_content: bytes,
    filename: str,
    document_type: DocumentChunk.DocumentType,
    title: str | None = None,
    replace_existing: bool = False,
) -> List[DocumentChunk]:
    """
    Asynchronously parse, chunk, embed, and persist DOCX content.

    This is the async version of ingest_docx for handling multiple files concurrently.

    Args:
        file_content: Raw bytes of the DOCX file
        filename: Name of the file
        document_type: Type of document (guideline or example)
        title: Optional title override
        replace_existing: Whether to replace existing documents with same title

    Returns:
        List of created DocumentChunk objects
    """
    # Parse DOCX in a thread pool (python-docx is not async)
    loop = asyncio.get_event_loop()

    def extract_segments():
        file_obj = io.BytesIO(file_content)
        document = Document(file_obj)
        segments = []
        for paragraph in document.paragraphs:
            text = paragraph.text.strip()
            if text:
                segments.append(text)
        return segments

    with ThreadPoolExecutor() as executor:
        segments = await loop.run_in_executor(executor, extract_segments)

    if not segments:
        raise ValueError("ูู ูุชู ุงูุนุซูุฑ ุนูู ูุต ุฏุงุฎู ุงูููู ุงููุฑููุน.")

    # Determine the final title
    final_title = title or filename or document_type

    # Check if a document with this title already exists (sync DB operation)
    @sync_to_async
    def check_existing():
        return DocumentChunk.objects.filter(
            document_type=document_type,
            title=final_title
        ).exists()

    existing_chunks = await check_existing()

    if existing_chunks and not replace_existing:
        raise ValueError(
            f"ููุฌุฏ ูุณุชูุฏ ุจููุณ ุงูุนููุงู '{final_title}' ุจุงููุนู. "
            "ุงูุฑุฌุงุก ุงุฎุชูุงุฑ ุนููุงู ุขุฎุฑ ุฃู ุญุฐู ุงููุณุชูุฏ ุงูููุฌูุฏ ุฃููุงู."
        )

    # Batch segments
    batches = _batch_segments(segments)

    # Embed texts asynchronously
    if len(batches) > 10:
        embeddings = await _async_embed_texts_chunked(batches)
    else:
        embeddings = await _async_embed_texts(batches)

    if len(batches) != len(embeddings):
        raise RuntimeError("Embedding count mismatch while processing DOCX.")

    # Save to database (sync operation wrapped in async)
    @sync_to_async
    def save_chunks():
        with transaction.atomic():
            if replace_existing:
                DocumentChunk.objects.filter(
                    document_type=document_type,
                    title=final_title
                ).delete()

            created_chunks: List[DocumentChunk] = []
            for idx, (text, embedding) in enumerate(zip(batches, embeddings)):
                chunk = DocumentChunk.objects.create(
                    document_type=document_type,
                    title=final_title,
                    source_name=filename,
                    order=idx,
                    text=text,
                    embedding=embedding,
                    metadata={"segment_count": len(text.splitlines())},
                )
                created_chunks.append(chunk)
            return created_chunks

    return await save_chunks()


async def async_ingest_multiple_docx(
    *,
    files_data: List[Tuple[bytes, str, Optional[str]]],  # (content, filename, title)
    document_type: DocumentChunk.DocumentType,
    replace_existing: bool = False,
    max_concurrent_files: int = 3,
) -> FileUploadBatch:
    """
    Asynchronously process multiple DOCX files concurrently.

    This function handles big data (multiple large files) efficiently by:
    1. Processing files concurrently with controlled parallelism
    2. Using async embeddings to avoid blocking
    3. Tracking progress at file and batch levels

    Args:
        files_data: List of (file_content_bytes, filename, optional_title) tuples
        document_type: Type of documents (guideline or example)
        replace_existing: Whether to replace existing documents with same titles
        max_concurrent_files: Maximum files to process concurrently

    Returns:
        FileUploadBatch object with processing results
    """
    # Create batch record
    @sync_to_async
    def create_batch():
        return FileUploadBatch.objects.create(
            document_type=document_type,
            status=FileUploadBatch.Status.PROCESSING,
            total_files=len(files_data),
        )

    batch = await create_batch()

    # Create file records
    @sync_to_async
    def create_file_records():
        records = []
        for content, filename, title in files_data:
            record = UploadedFile.objects.create(
                batch=batch,
                filename=filename,
                title=title or "",
                file_size=len(content),
                status=UploadedFile.Status.PENDING,
            )
            records.append(record)
        return records

    file_records = await create_file_records()

    results = {
        "total_chunks": 0,
        "processed": 0,
        "errors": [],
    }

    semaphore = asyncio.Semaphore(max_concurrent_files)

    async def process_file(
        file_data: Tuple[bytes, str, Optional[str]],
        file_record: UploadedFile
    ):
        async with semaphore:
            content, filename, title = file_data

            @sync_to_async
            def update_status(status, chunks=0, error=""):
                file_record.status = status
                if chunks:
                    file_record.chunks_created = chunks
                if error:
                    file_record.error_message = error
                file_record.save()

            try:
                await update_status(UploadedFile.Status.PROCESSING)

                chunks = await async_ingest_docx(
                    file_content=content,
                    filename=filename,
                    document_type=document_type,
                    title=title,
                    replace_existing=replace_existing,
                )

                await update_status(UploadedFile.Status.COMPLETED, len(chunks))
                results["total_chunks"] += len(chunks)
                results["processed"] += 1

            except Exception as e:
                error_msg = str(e)
                await update_status(UploadedFile.Status.FAILED, error=error_msg)
                results["errors"].append(f"{filename}: {error_msg}")
                logger.error(f"Error processing {filename}: {e}")

            # Update batch progress
            @sync_to_async
            def update_batch_progress():
                batch.processed_files = results["processed"]
                batch.total_chunks_created = results["total_chunks"]
                batch.save()

            await update_batch_progress()

    # Process all files concurrently
    await asyncio.gather(*[
        process_file(file_data, file_record)
        for file_data, file_record in zip(files_data, file_records)
    ])

    # Update final batch status
    @sync_to_async
    def finalize_batch():
        if results["errors"]:
            if results["processed"] == 0:
                batch.status = FileUploadBatch.Status.FAILED
            else:
                batch.status = FileUploadBatch.Status.COMPLETED  # Partial success
            batch.error_message = "\n".join(results["errors"])
        else:
            batch.status = FileUploadBatch.Status.COMPLETED
        batch.save()

    await finalize_batch()

    # Refresh batch from DB
    @sync_to_async
    def refresh_batch():
        batch.refresh_from_db()
        return batch

    return await refresh_batch()


def _cosine_similarity(vec_a: Sequence[float], vec_b: Sequence[float]) -> float:
    dot_product = 0.0
    mag_a = 0.0
    mag_b = 0.0
    for a, b in zip(vec_a, vec_b):
        dot_product += a * b
        mag_a += a * a
        mag_b += b * b
    if mag_a == 0.0 or mag_b == 0.0:
        return 0.0
    return dot_product / ((mag_a ** 0.5) * (mag_b ** 0.5))


def retrieve_similar_chunks(
    *,
    query_text: str,
    document_type: DocumentChunk.DocumentType,
    limit: int | None = 3,
) -> List[RetrievedChunk]:
    chunks = list(DocumentChunk.objects.filter(document_type=document_type))
    if not chunks:
        return []

    query_embedding = _embed_texts([query_text])[0]
    scored = [
        RetrievedChunk(chunk=chunk, similarity=_cosine_similarity(query_embedding, chunk.embedding))
        for chunk in chunks
    ]
    scored.sort(key=lambda item: item.similarity, reverse=True)
    if limit is None or limit >= len(scored):
        return scored
    return scored[:limit]


def _preprocess_honorifics(text: str) -> str:
    """
    Preprocess text to remove excessive honorifics while keeping official titles.

    IMPORTANT: This function preserves quoted text (text within quotation marks) unchanged.

    KEEP (Official Titles):
    - ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู (official title for Saudi King)
    - ุตุงุญุจ ุงูุณูู ุงููููู (official title for Royal Highness)

    REMOVE (Exaggerated Phrases):
    - ุฌูุงูุฉ ุงูููู ุงููุนุธู ุฃูุฏู ุงููู โ ุงูููู
    - ูุฎุงูุฉ ุงูุฑุฆูุณ ุญูุธู ุงููู โ ุงูุฑุฆูุณ
    - Prayer phrases: ุญูุธู ุงูููุ ุฃูุฏู ุงูููุ ุฑุนุงู ุงููู
    - Exaggerated adjectives: ุงููุนุธูุ ุงูุฌููู
    """
    # Step 1: Extract and preserve quoted text
    # Match various quotation mark styles: "...", ยซ...ยป, "...", '...'
    quote_patterns = [
        r'"([^"]+)"',      # Standard quotes
        r'ยซ([^ยป]+)ยป',      # Arabic quotes
        r'"([^"]+)"',      # Curly double quotes
        r"'([^']+)'",      # Single curly quotes
    ]

    # Store quoted texts with placeholders
    quoted_texts = []
    processed_text = text

    for pattern in quote_patterns:
        matches = re.finditer(pattern, processed_text)
        for match in matches:
            placeholder = f"<<<QUOTE_{len(quoted_texts)}>>>"
            quoted_texts.append(match.group(0))  # Store the full match including quotes
            processed_text = processed_text.replace(match.group(0), placeholder, 1)

    # Define comprehensive replacement patterns (order matters - most specific first)
    replacements = [
        # King honorifics - REMOVE exaggerated parts, keep simple title
        # "ุฌูุงูุฉ ุงูููู ุงููุนุธู" โ "ุงูููู" (remove exaggeration)
        (r'ุฌูุงูุฉ\s+ุงูููู\s+ุงููุนุธู', 'ุงูููู'),
        (r'ุฌูุงูุฉ\s+ุงูููู', 'ุงูููู'),
        (r'ุญุถุฑุฉ\s+ุตุงุญุจ\s+ุงูุฌูุงูุฉ\s+ุงูููู\s+ุงููุนุธู', 'ุงูููู'),
        (r'ุญุถุฑุฉ\s+ุตุงุญุจ\s+ุงูุฌูุงูุฉ\s+ุงูููู', 'ุงูููู'),
        (r'ุตุงุญุจ\s+ุงูุฌูุงูุฉ\s+ุงูููู\s+ุงููุนุธู', 'ุงูููู'),
        (r'ุตุงุญุจ\s+ุงูุฌูุงูุฉ\s+ุงูููู', 'ุงูููู'),
        (r'ุงูููู\s+ุงููุนุธู', 'ุงูููู'),

        # Sultan honorifics - REMOVE exaggerated parts
        (r'ุญุถุฑุฉ\s+ุตุงุญุจ\s+ุงูุฌูุงูุฉ\s+ุงูุณูุทุงู\s+ุงููุนุธู', 'ุงูุณูุทุงู'),
        (r'ุญุถุฑุฉ\s+ุตุงุญุจ\s+ุงูุฌูุงูุฉ\s+ุงูุณูุทุงู', 'ุงูุณูุทุงู'),
        (r'ุตุงุญุจ\s+ุงูุฌูุงูุฉ\s+ุงูุณูุทุงู\s+ุงููุนุธู', 'ุงูุณูุทุงู'),
        (r'ุตุงุญุจ\s+ุงูุฌูุงูุฉ\s+ุงูุณูุทุงู', 'ุงูุณูุทุงู'),
        (r'ุฌูุงูุฉ\s+ุงูุณูุทุงู', 'ุงูุณูุทุงู'),
        (r'ุงูุณูุทุงู\s+ุงููุนุธู', 'ุงูุณูุทุงู'),

        # President honorifics - REMOVE "ูุฎุงูุฉ" but this is less common in Gulf news
        (r'ูุฎุงูุฉ\s+ุงูุฑุฆูุณ', 'ุงูุฑุฆูุณ'),

        # Prince titles - KEEP "ุตุงุญุจ ุงูุณูู ุงููููู" as it's an official title
        # But remove exaggerated adjectives like "ุงูุฌููู" or "ุงููุฑูู" when standalone
        (r'ุณููู\s+ุงููุฑูู', 'ุณููู'),
        (r'ุณููู\s+ุงูุฌููู', 'ุณููู'),

        # Prayer phrases - DELETE completely (these are pure exaggeration, not titles)
        (r'\s+ุญูุธู\s+ุงููู\s+', ' '),
        (r'\s+ุญูุธูุง\s+ุงููู\s+', ' '),
        (r'\s+ุฑุนุงู\s+ุงููู\s+', ' '),
        (r'\s+ุฑุนุงูุง\s+ุงููู\s+', ' '),
        (r'\s+ูุตุฑู\s+ุงููู\s+', ' '),
        (r'\s+ุฃูุฏู\s+ุงููู\s+', ' '),
        (r'\s+ุฃุทุงู\s+ุงููู\s+ุนูุฑู\s+', ' '),
        (r'\s+ุฃุฏุงู\s+ุงููู\s+ุนุฒู\s+', ' '),
        (r'\s+ุญูุธููุง\s+ุงููู\s+', ' '),
        (r'\s+ุญูุธูู\s+ุงููู\s+', ' '),
        (r'\s+ุญูุธู\s+ุงููู\s*$', ' '),  # At end of sentence
        (r'^\s*ุญูุธู\s+ุงููู\s+', ' '),  # At start of sentence

        # Exaggerated adjectives - DELETE
        (r'\bุฎุงูุต\s+', ''),  # "ุฎุงูุต ุชูุงููู" โ "ุชูุงููู"
        (r'\bุงูุฌููู\s+', ''),  # When used as standalone adjective
    ]

    # Step 2: Apply all replacements (to non-quoted text)
    for pattern, replacement in replacements:
        processed_text = re.sub(pattern, replacement, processed_text, flags=re.IGNORECASE)

    # Step 3: Clean up multiple spaces and trim
    processed_text = re.sub(r'\s+', ' ', processed_text)
    processed_text = processed_text.strip()

    # Step 4: Restore quoted texts
    for i, quoted_text in enumerate(quoted_texts):
        placeholder = f"<<<QUOTE_{i}>>>"
        processed_text = processed_text.replace(placeholder, quoted_text)

    return processed_text


def build_review_prompt(news_text: str, guidelines: Iterable[RetrievedChunk], examples: Iterable[RetrievedChunk]) -> List[dict]:
    # Preprocess text to handle honorifics before sending to AI
    processed_news_text = _preprocess_honorifics(news_text)
    
    guideline_section_lines = []
    for idx, item in enumerate(guidelines, start=1):
        guideline_section_lines.append(f"{idx}. {item.chunk.text}")
    guideline_section = "\n".join(guideline_section_lines) if guideline_section_lines else "No guidelines available."

    example_section_lines = []
    for idx, item in enumerate(examples, start=1):
        example_section_lines.append(f"### Example {idx}\n{item.chunk.text}")
    example_section = "\n\n".join(example_section_lines) if example_section_lines else "No examples available."

    user_prompt = (
        "๐ด๐ด๐ด ุชุนูููุงุช ุตุงุฑูุฉ - ุงูุฑุฃูุง ุจุนูุงูุฉ! ๐ด๐ด๐ด\n\n"
        "โ ูุง ุชูุนูุฏ ุตูุงุบุฉ ุงูุฎุจุฑ! โ\n"
        "โ ูุง ุชูุบููุฑ ูููุงุช ุงูุฎุจุฑ ุงูุฃุตูู! โ\n"
        "โ ูุง ุชูุถูู ุฃู ูุนูููุงุช ุฌุฏูุฏุฉ! โ\n\n"
        "โ ููุท ุทุจูู ูุฐู ุงูุชุนุฏููุงุช ุงููุญุฏุฏุฉ:\n"
        "1. ุฃุถู ุงูุฌูุณูุฉ ูููุณุคูู ูู ุงูุนููุงู (ุฅุฐุง ูู ุชูู ููุฌูุฏุฉ)\n"
        "2. ุฃุถู ุณุทุฑ ุงููุฏููุฉ ูุงูููุงูุฉ ูู ุงูุจุฏุงูุฉ (ุฅุฐุง ูู ููู ููุฌูุฏุงู)\n"
        "3. ุฃุฒู ุงูุฃููุงุจ ุงููุจุงูุบ ูููุง (ุฌูุงูุฉุ ูุฎุงูุฉุ ุญูุธู ุงููู...)\n"
        "4. ุฃุถู (ุงูุชูู) ูู ุงูููุงูุฉ\n"
        "5. ุตุญุญ ุงูุฃุฎุทุงุก ุงูุฅููุงุฆูุฉ ููุท\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "๐ด ูุงุนุฏุฉ ุงูุฌูุณูุฉ ูู ุงูุนูุงููู ๐ด\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "ุฃุถู ุงูุฌูุณูุฉ ุจุนุฏ ุงูููุตุจ ุฃู ุงููุฒุงุฑุฉ ูุจุงุดุฑุฉ:\n"
        "โข 'ุฑุฆูุณ ุงููุฒุฑุงุก' โ 'ุฑุฆูุณ ุงููุฒุฑุงุก ุงูุนุฑุงูู'\n"
        "โข 'ุงูููู' โ 'ุงูููู ุงูุณุนูุฏู'\n"
        "โข 'ุงูุฎุงุฑุฌูุฉ' โ 'ุงูุฎุงุฑุฌูุฉ ุงูุณุนูุฏูุฉ' ุฃู 'ุงูุฎุงุฑุฌูุฉ ุงููุตุฑูุฉ'\n"
        "โข 'ูุฒูุฑ ุงูุณูุงุญุฉ' โ 'ูุฒูุฑ ุงูุณูุงุญุฉ ุงูุณุนูุฏู'\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "๐ด ูุงุนุฏุฉ ุงุฎุชุตุงุฑ ุฃุณูุงุก ุงููุฒุงุฑุงุช - ููู ุฌุฏุงู! ๐ด\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "ุงุณุชุฎุฏู ุงูุตูุบุฉ ุงููุฎุชุตุฑุฉ ูููุฒุงุฑุงุช (ุจุฏูู ูููุฉ 'ูุฒุงุฑุฉ'):\n"
        "โข 'ูุฒุงุฑุฉ ุงูุฎุงุฑุฌูุฉ ุงูุนุฑุงููุฉ' โ 'ุงูุฎุงุฑุฌูุฉ ุงูุนุฑุงููุฉ'\n"
        "โข 'ูุฒุงุฑุฉ ุงูุฎุงุฑุฌูุฉ ุงูุณุนูุฏูุฉ' โ 'ุงูุฎุงุฑุฌูุฉ ุงูุณุนูุฏูุฉ'\n"
        "โข 'ูุฒุงุฑุฉ ุงูุฎุงุฑุฌูุฉ ุงููุตุฑูุฉ' โ 'ุงูุฎุงุฑุฌูุฉ ุงููุตุฑูุฉ'\n"
        "โข 'ูุฒุงุฑุฉ ุงูุฏูุงุน ุงูุจุงูุณุชุงููุฉ' โ 'ุงูุฏูุงุน ุงูุจุงูุณุชุงููุฉ'\n"
        "โข 'ูุฒุงุฑุฉ ุงูุฏุงุฎููุฉ ุงูุฅูุงุฑุงุชูุฉ' โ 'ุงูุฏุงุฎููุฉ ุงูุฅูุงุฑุงุชูุฉ'\n"
        "โข 'ูุฒุงุฑุฉ ุงูุตุญุฉ ุงูุณุนูุฏูุฉ' โ 'ุงูุตุญุฉ ุงูุณุนูุฏูุฉ'\n\n"
        "โ๏ธ ุงุณุชุซูุงุก: 'ูุฒุงุฑุฉ ุงูุญุฌ ูุงูุนูุฑุฉ' ุชุจูู ููุง ูู ุจุฏูู ุงุฎุชุตุงุฑ (ูุฃููุง ูุญูุฏุฉ ูู ุงูุนุงูู)\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "๐ด ูุตุทูุญุงุช ุงููุถูุฉ ุงูููุณุทูููุฉ - ุงุณุชุฎุฏู ุงููุตุทูุญ ุงูุตุญูุญ! ๐ด\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "ุงุณุชุจุฏู ุงููุตุทูุญุงุช ุงูุชุงููุฉ ุจุงูุดูู ุงูุตุญูุญ:\n"
        "โข 'ุณูุงู ุงููุฏุณ' โ 'ุงูููุฏุณููู'\n"
        "โข 'ุดุฑูู ุงููุฏุณ' โ 'ุงููุฏุณ ุงููุญุชูุฉ'\n"
        "โข 'ุนุฑุจ ุฅุณุฑุงุฆูู' ุฃู 'ุนุฑุจ ุงุณุฑุงุฆูู' โ 'ููุณุทูููู 48'\n"
        "โข 'ุงูุฌุฏุงุฑ ุงูุนุงุฒู' โ 'ุฌุฏุงุฑ ุงููุตู ุงูุนูุตุฑู'\n"
        "โข 'ุงูุฃุฑุงุถู ุงููุชูุงุฒุน ุนูููุง' โ 'ุงูุฃุฑุถ ุงูููุณุทูููุฉ ุงููุญุชูุฉ'\n"
        "โข 'ุฌูุด ุงูุฏูุงุน' ุฃู 'ุฌูุด ุงูุฏูุงุน ุงูุฅุณุฑุงุฆููู' โ 'ุฌูุด ุงูุงุญุชูุงู ุงูุฅุณุฑุงุฆููู'\n"
        "โข 'ุดุนุจ ุบุฒุฉ' โ 'ุงูููุงุทููู ุงูููุณุทููููู ูู ูุทุงุน ุบุฒุฉ'\n"
        "โข 'ุงูุญูููุฉ ุงูุฅุณุฑุงุฆูููุฉ' โ 'ุญูููุฉ ุงูุงุญุชูุงู ุงูุฅุณุฑุงุฆููู'\n\n"
        "ููู ุชุนุฑู ุงูุฌูุณูุฉุ\n"
        "โข ูุงุน = ุนุฑุงูู | ูุงุณ = ุณุนูุฏู | ูุงู = ุฅูุงุฑุงุชู | ููููุง = ูููุชู | ุจูุง = ุจุญุฑููู\n"
        "โข ุจุบุฏุงุฏ = ุนุฑุงูู | ุงูุฑูุงุถ = ุณุนูุฏู | ุงููุงูุฑุฉ = ูุตุฑู | ุงููููุช = ูููุชู\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "๐ด๐ด๐ด ุงููููู ุงููุทููุจ - ููู ุฌุฏุงู! ๐ด๐ด๐ด\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "โ๏ธ ุงูุนููุงู ูุฌุจ ุฃู ูููู ูู ุณุทุฑ ูููุตู ุชูุงูุงู! โ๏ธ\n\n"
        "ุงููููู:\n"
        "ุงูุณุทุฑ 1: ุงูุนููุงู (ูุน ุงูุฌูุณูุฉ)\n"
        "ุงูุณุทุฑ 2: [ุณุทุฑ ูุงุฑุบ]\n"
        "ุงูุณุทุฑ 3: ุงููุฏููุฉ (ูููุง/ุงูููุงูุฉ) - ูุต ุงูุฎุจุฑ\n"
        "ุงูุณุทุฑ 4: [ุณุทุฑ ูุงุฑุบ]\n"
        "ุงูุณุทุฑ 5: (ุงูุชูู)\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "๐ ูุซุงู ุนููู - ุงูุชุจู ููุฃุณุทุฑ ุงููุงุฑุบุฉ!\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "โ ุฎุทุฃ (ุงูุนููุงู ููุชุตู ุจุงููุชู):\n"
        "ุฑุฆูุณ ุงููุฒุฑุงุก ุงูุนุฑุงูู: ุฃูุดุฃูุง 15 ูุตุญุฉ ุจุบุฏุงุฏ (ูููุง/ูุงุน) - ุฃูุฏ...\n\n"
        "โ ุตุญูุญ (ุงูุนููุงู ูู ุณุทุฑ ูููุตู):\n"
        "ุฑุฆูุณ ุงููุฒุฑุงุก ุงูุนุฑุงูู: ุฃูุดุฃูุง 15 ูุตุญุฉ ูุณุฑูุฉ\n\n"
        "ุจุบุฏุงุฏ (ูููุง/ูุงุน) - ุฃูุฏ ุฑุฆูุณ ุงููุฒุฑุงุก ุงูุนุฑุงูู ูุญูุฏ ุดูุงุน ุงูุณูุฏุงูู ุฃู ุงูุญูููุฉ ุฃูุดุฃุช 15 ูุตุญุฉ.\n\n"
        "(ุงูุชูู)\n\n"
        "โ๏ธ ูุงุญุธ: ุจูู ุงูุนููุงู ูุจูู ุณุทุฑ ุงููุฏููุฉ ููุฌุฏ ุณุทุฑ ูุงุฑุบ (\\n\\n)!\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "๐ด๐ด๐ด ููุงุนุฏ ุฅูุฒุงููุฉ ุนูู ูุนุงูุฌ ุงูุฃุฎุจุงุฑ - ูุฌุจ ุชุทุจูููุง ุฌููุนุงู! ๐ด๐ด๐ด\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
        "โ ุงููุงุนุฏุฉ 1 - ุงูุนููุงู ูู ุณุทุฑ ูุณุชูู (ุฅูุฒุงูู):\n"
        "   โข ูุฌุจ ุฃู ูููู ุงูุนููุงู ูู ุณุทุฑ ูููุตู ุชูุงูุงู ุนู ุจุงูู ุงูุฎุจุฑ\n"
        "   โข ูุชุจุนู ุณุทุฑ ูุงุฑุบ ุซู ุงููุชู\n\n"
        "โ ุงููุงุนุฏุฉ 2 - ูููุฉ (ุงูุชูู) ูู ุณุทุฑ ูุณุชูู (ุฅูุฒุงูู):\n"
        "   โข ูุฌุจ ุฃู ุชููู (ุงูุชูู) ูู ุขุฎุฑ ุณุทุฑ ูููุตู\n"
        "   โข ูุณุจููุง ุณุทุฑ ูุงุฑุบ\n\n"
        "โ ุงููุงุนุฏุฉ 3 - ุฐูุฑ ุงุณู ุงูููุงูุฉ ุงููุตุฏุฑ (ุฅูุฒุงูู):\n"
        "   โข ูุฌุจ ูุชุงุจุฉ ุงุณู ุงูููุงูุฉ ุงููุตุฏุฑ ุจุนุฏ (ูููุง/)\n"
        "   โข โ ุฎุทุฃ: ุทูุจุงุณ (ูููุง) โ\n"
        "   โข โ ุตุญูุญ: ุทูุจุงุณ (ูููุง/ุงูุบุฏ) โ\n"
        "   โข โ ุตุญูุญ: ุจุบุฏุงุฏ (ูููุง/ูุงุน) โ\n"
        "   โข โ ุตุญูุญ: ุงูุฑูุงุถ (ูููุง/ูุงุณ) โ\n\n"
        "โ ุงููุงุนุฏุฉ 4 - ุทูู ุงูุนููุงู (ุฅูุฒุงูู):\n"
        "   โข ูุฌุจ ุฃูุง ูุชุฌุงูุฒ ุงูุนููุงู 12 ูููุฉ\n"
        "   โข ุฅุฐุง ูุงู ุฃุทููุ ุงุฎุชุตุฑู ูุน ุงูุญูุงุธ ุนูู ุงููุนูู\n\n"
        "โ ุงููุงุนุฏุฉ 5 - ุทูู ุงูููุฑุฉ (ุฅูุฒุงูู):\n"
        "   โข ูุฌุจ ุฃูุง ูุฒูุฏ ุนุฏุฏ ุงููููุงุช ูู ูู ููุฑุฉ ุนู 50 ูููุฉ\n"
        "   โข ูุณูู ุงูููุฑุงุช ุงูุทูููุฉ ุฅูู ููุฑุงุช ุฃูุตุฑ\n\n"
        "โ ุงููุงุนุฏุฉ 6 - ุงุณุชุจุฏุงู 'ูุฑุงุณููุง/ูุฑุงุณูุชูุง' (ุฅูุฒุงูู):\n"
        "   โข ูุฌุจ ุงุณุชุจุฏุงู 'ูุฑุงุณููุง' ุฃู 'ูุฑุงุณูุชูุง' ุจุงุณู ุงูููุงูุฉ ุงููุตุฏุฑ ุงูุฃุตููุฉ (ูููุณ ูููุง!)\n"
        "   โข ุงูุธุฑ ุฅูู ูุตุฏุฑ ุงูุฎุจุฑ ูู (ูููุง/XXX) ูุงุณุชุฎุฏู XXX\n"
        "   โข โ ุฎุทุฃ: ุฃูุงุฏ ูุฑุงุณููุง\n"
        "   โข โ ุฎุทุฃ: ุฃูุงุฏ ูุฑุงุณู ูููุง (ูููุง ููุณุช ุงููุตุฏุฑ ุงูุฃุตูู!)\n"
        "   โข โ ุตุญูุญ: ุฃูุงุฏ ูุฑุงุณู ููุงุฉ ุงูุบุฏ (ุฅุฐุง ูุงู ุงููุตุฏุฑ ุงูุบุฏ)\n"
        "   โข โ ุตุญูุญ: ุฃูุงุฏ ูุฑุงุณู ูุงุน (ุฅุฐุง ูุงู ุงููุตุฏุฑ ูุงุน)\n"
        "   โข โ ุตุญูุญ: ุฃูุงุฏ ูุฑุงุณู ูุงุณ (ุฅุฐุง ูุงู ุงููุตุฏุฑ ูุงุณ)\n"
        "   โข ๐ด ููู: ูููุง ูู ุงููุงููุฉ ูููุณุช ุงููุตุฏุฑ ุงูุฃุตูู!\n\n"
        "โ ุงููุงุนุฏุฉ 7 - ุงูุชูููุน ูู ุงูุฃูุนุงู ุงูุฅุนูุงููุฉ (ุฅูุฒุงูู):\n"
        "   โข ููููุน ุชูุฑุงุฑ ููุณ ุงููุนู ุงูุฅุนูุงูู ุฃูุซุฑ ูู ูุฑุฉ ูู ุงูุฎุจุฑ\n"
        "   โข ุฅุฐุง ุงุณุชุฎุฏูุช 'ุฃูุงุฏ' ูู ุงูููุฑุฉ ุงูุฃูููุ ุงุณุชุฎุฏู ูุนูุงู ูุฎุชููุงู ูู ุงูููุฑุฉ ุงูุซุงููุฉ\n"
        "   โข ุงูุฃูุนุงู ุงููุชุงุญุฉ: ูุงูุ ุฐูุฑุ ุฃูุถุญุ ุฃูุฏุ ุดุฏูุฏุ ุจูููุ ุฃุดุงุฑุ ุฃูุงุฏุ ุฃุนููุ ุฃูุตุญุ ุนุจูุฑุ ุฃุนุฑุจุ ููููุ ุฃุจุงูุ\n"
        "     ูุดูุ ููุชุ ุฑุฌูุญุ ุฌุฒูุ ูููุ ุฃุถุงูุ ุชุงุจุนุ ุฎุชูุ ุฃูุฑุฏุ ูููุ ุญุฏูุฏุ ุฏุนุงุ ุทุงูุจุ ุญุฐูุฑุ ุงุณุชููุฑุ ูุฏูุฏุ\n"
        "     ุฑุญูุจุ ุฃุจุฏูุ ุงุนุชุจุฑุ ุฑุฃูุ ุชูููุนุ ุฃูุตูุ ุทุฑุญุ ุฃูุนุฒุ ูุฌููุ ุงุณุชุนุฑุถุ ุตุฑูุญุ ุฃุฎุจุฑุ ุฃุจูุบุ ุฃุทูุนุ ุฃุจุฑุฒุ ุฃุธูุฑ\n"
        "   โข ูุซุงู:\n"
        "     โ ุฎุทุฃ: ุฃูุงุฏ ูุฑุงุณู... ูุฃุถุงู ุฃู...\n"
        "     โ ุตุญูุญ: ุฃูุงุฏ ูุฑุงุณู... ูุฃูุถุญ ุฃู... / ูุจููู ุฃู... / ูููุช ุฅูู ุฃู...\n\n"
        "โ ุงููุงุนุฏุฉ 8 - ุชูุงุณู ุงูุฌูู ูุฃุฏูุงุช ุงูุฑุจุท (ุฅูุฒุงูู):\n"
        "   โข ูุฌุจ ุงูุญูุงุธ ุนูู ุชูุงุณู ุงูุฌูู ูุฑุจุทูุง ุจุณูุงุณุฉ\n"
        "   โข ุงุณุชุฎุฏู ุฃุฏูุงุช ุงูุฑุจุท ุงูููุงุณุจุฉ: ูุ ููุงุ ูููุงุ ุจูููุงุ ูู ุญููุ ุฅุถุงูุฉ ุฅูู ุฐููุ ุนูุงูุฉ ุนูู ุฐูู\n\n"
        "โ ุงููุงุนุฏุฉ 9 - ูุตุทูุญุงุช ููุณุทูู (ุฅูุฒุงูู):\n"
        "   โข ูู ุฃุฎุจุงุฑ ููุณุทูู ููููุน ุงุณุชุฎุฏุงู: ููุชูุ ูุตุฑุนุ ููุชุ ูุชููุ ูุชูู\n"
        "   โข ูุฌุจ ุงุณุชุฎุฏุงู: ุงุณุชุดูุงุฏุ ุดููุฏุ ุดูุฏุงุก\n"
        "   โข โ ุฎุทุฃ: ููุชู 5 ููุณุทููููู\n"
        "   โข โ ุตุญูุญ: ุงุณุชุดูุงุฏ 5 ููุณุทููููู\n"
        "   โข โ ุฎุทุฃ: ุฌูุด ุงูุฏูุงุน ุงูุฅุณุฑุงุฆููู\n"
        "   โข โ ุตุญูุญ: ุฌูุด ุงูุงุญุชูุงู ุงูุฅุณุฑุงุฆููู\n\n"
        "โ ุงููุงุนุฏุฉ 10 - ุตูุบุฉ ุงูุชุงุฑูุฎ (ุฅูุฒุงูู):\n"
        "   โข ูุฌุจ ูุชุงุจุฉ ุงูุชุงุฑูุฎ ุจุงููููุงุฏู ููุท ุจูุฐู ุงูุตูุบุฉ: ุงูููู DD ุงูุดูุฑ YYYYู\n"
        "   โข โ ุตุญูุญ: ุงูุฃุญุฏ 21 ุฏูุณูุจุฑ 2025ู\n"
        "   โข โ ุตุญูุญ: ุงูุฎููุณ 5 ููุงูุฑ 2025ู\n"
        "   โข โ ุฎุทุฃ: 21 ูุงููู ุงูุฃูู (ุดููุฑ ุณุฑูุงููุฉ ููููุนุฉ)\n"
        "   โข โ ุฎุทุฃ: 15 ุฌูุงุฏู ุงูุฃููู 1446ูู (ุดููุฑ ูุฌุฑูุฉ ููููุนุฉ)\n\n"
        "โ ุงููุงุนุฏุฉ 11 - ุงูุตูุงุช ุงูุชูุฑูุฑูุฉ (ุฅูุฒุงูู):\n"
        "   โข ููููุน ุงุณุชุฎุฏุงู ุงูุตูุงุช ุงูุชูุฑูุฑูุฉ ุจุฏูู ุฏููู\n"
        "   โข ุงูุตูุงุช ุงูููููุนุฉ: ุถุฎูุ ุบูุฑ ูุณุจููุ ุชุงุฑูุฎูุ ูุงุฆูุ ูุจูุฑ ุฌุฏุงู\n"
        "   โข ููุณูุญ ุจูุง ููุท ุฅุฐุง ูุงูุช ูุฏุนููุฉ ุจุจูุงูุงุช ุฃู ุฃุฑูุงู ูุญุฏุฏุฉ\n\n"
        "โ ุงููุงุนุฏุฉ 12 - ุงูุฃููุงุณ (ุฅูุฒุงูู):\n"
        "   โข ุชุฌูุจ ุงูุฅูุฑุงุท ูู ุงุณุชุฎุฏุงู ุงูุฃููุงุณ\n"
        "   โข ุงุณุชุฎุฏู ุงูุฃููุงุณ ููุท ุนูุฏ ุงูุถุฑูุฑุฉ ุงููุตูู\n\n"
        "โ ุงููุงุนุฏุฉ 13 - ุงูุชูุฑุงุฑ (ุฅูุฒุงูู):\n"
        "   โข ููููุน ุงูุชูุฑุงุฑ ุบูุฑ ุงููุจุฑุฑ ููุฌูู ุฃู ุงูุนุจุงุฑุงุช\n"
        "   โข ุฅุฐุง ุฐููุฑุช ูุนูููุฉ ูุฑุฉุ ูุง ุชููุฑุฑูุง\n\n"
        "โ ุงููุงุนุฏุฉ 14 - ุนูุงูุงุช ุงูุชุฑููู (ุฅูุฒุงูู):\n"
        "   โข ูุฌุจ ุงูุงูุชูุงู ุจุนูุงูุงุช ุงูุชุฑููู (ุงูููุงุตู ูุงูููุงุท)\n"
        "   โข ูุฐุง ุจููุณ ุฃูููุฉ ุชุตุญูุญ ุงูุฃุฎุทุงุก ุงูุฅููุงุฆูุฉ\n"
        "   โข ุชุฃูุฏ ูู ูุฌูุฏ ูุงุตูุฉ ุจูู ุงูุฌูู ุงููุนุทููุฉ\n"
        "   โข ุชุฃูุฏ ูู ูุฌูุฏ ููุทุฉ ูู ููุงูุฉ ูู ููุฑุฉ\n\n"
        "๐จ๐จ๐จ ุชุญุฐูุฑ: ุฅุฐุง ูู ุชูุทุจู ุฃู ูู ูุฐู ุงูููุงุนุฏุ ูุฃูุช ูุฏ ูุดูุช! ๐จ๐จ๐จ\n\n"
        "### Editorial Guidelines\n"
        f"{guideline_section}\n\n"
        "### Reference News Examples\n"
        f"{example_section}\n\n"
        "### Article Requiring Review\n"
        f"{processed_news_text}\n\n"
        "FIRST: Validate that the text above is a legitimate news article. "
        "If it is random, inappropriate, meaningless, or not a news article, "
        "respond ONLY with: 'ERROR: ุงููุต ุงูููุฏู ุบูุฑ ููุงุณุจ ุฃู ุบูุฑ ุตุงูุญ ูููุนุงูุฌุฉ. ูุฑุฌู ุชูุฏูู ุฎุจุฑ ุตุญูุญ.'\n\n"
        "โ๏ธโ๏ธโ๏ธ CRITICAL RULE: UNDERSTAND THE DIFFERENCE BETWEEN OFFICIAL TITLES AND EXAGGERATION โ๏ธโ๏ธโ๏ธ\n\n"
        "๐ด ABSOLUTE RULE - READ THIS CAREFULLY:\n"
        "There is a HUGE difference between:\n"
        "1. OFFICIAL STATE TITLES (ุงูุฃููุงุจ ุงูุฑุณููุฉ ููุฏููุฉ) = These are REAL titles, NOT exaggeration โ MUST KEEP\n"
        "2. EXAGGERATED PHRASES (ุงูุชูุฎูู ูุงูุชุนุธูู) = These are praise phrases, NOT titles โ MUST REMOVE\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "โ WHAT TO KEEP - THESE ARE OFFICIAL TITLES (DO NOT TOUCH!):\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "1. โ 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' - Official title of Saudi King (like a last name)\n"
        "   Why? This is his OFFICIAL STATE TITLE, not exaggeration!\n"
        "   โ๏ธ NEVER remove this! It's like removing someone's official job title!\n\n"
        "2. โ 'ุตุงุญุจ ุงูุณูู ุงููููู' - Official Royal Highness title (government-recognized)\n"
        "   Why? This is the OFFICIAL PROTOCOL title for princes, grandson of the King!\n"
        "   โ๏ธ NEVER remove this! It's their official designation in the state!\n\n"
        "3. โ 'ููู ุงูุนูุฏ' - Official Crown Prince position\n"
        "4. โ 'ุฑุฆูุณ ูุฌูุณ ุงููุฒุฑุงุก' - Official Prime Minister position\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "โ WHAT TO REMOVE - THESE ARE EXAGGERATION (DELETE OR SIMPLIFY!):\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "1. โ 'ุฌูุงูุฉ ุงูููู ุงููุนุธู ุฃูุฏู ุงููู' โ โ 'ุงูููู'\n"
        "   Why? 'ุฌูุงูุฉ' and 'ุงููุนุธู' and 'ุฃูุฏู ุงููู' are EXAGGERATION, not official titles!\n\n"
        "2. โ 'ุฌูุงูุฉ ุงูููู' โ โ 'ุงูููู'\n"
        "3. โ 'ุญุถุฑุฉ ุตุงุญุจ ุงูุฌูุงูุฉ ุงูููู' โ โ 'ุงูููู'\n"
        "4. โ 'ุตุงุญุจ ุงูุฌูุงูุฉ ุงูุณูุทุงู' โ โ 'ุงูุณูุทุงู'\n"
        "5. โ 'ูุฎุงูุฉ ุงูุฑุฆูุณ' โ โ 'ุงูุฑุฆูุณ'\n"
        "6. โ Prayer phrases: 'ุญูุธู ุงููู', 'ุฃูุฏู ุงููู', 'ุฑุนุงู ุงููู', 'ูุตุฑู ุงููู' โ DELETE COMPLETELY\n"
        "7. โ Exaggeration words: 'ุงููุนุธู', 'ุงูุฌููู', 'ุฎุงูุต' โ DELETE\n"
        "8. โ 'ุณููู ุงููุฑูู' โ โ 'ุณููู'\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "๐ KEY DISTINCTION (READ THIS 10 TIMES!):\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "โข 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' = Official title (like saying 'Dr.' or 'President') โ KEEP!\n"
        "โข 'ุตุงุญุจ ุงูุณูู ุงููููู' = Official royal protocol title โ KEEP!\n"
        "โข 'ุฌูุงูุฉ ุงูููู ุงููุนุธู' = Exaggerated praise โ REMOVE, simplify to 'ุงูููู'\n"
        "โข 'ุญูุธู ุงููู' 'ุฃูุฏู ุงููู' = Prayer/supplication โ DELETE COMPLETELY\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "๐ MANDATORY EXAMPLES - STUDY THESE CAREFULLY:\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
        "Example 1 - Removing exaggeration, keeping simple title:\n"
        "โ BEFORE: 'ุจุนุซ ุฌูุงูุฉ ุงูููู ุงููุนุธู ุญูุฏ ุจู ุนูุณู ุขู ุฎูููุฉ ุญูุธู ุงููู ุจุฑููุฉ ุชููุฆุฉ ุฎุงูุตุฉ'\n"
        "โ AFTER:  'ุจุนุซ ุงูููู ุญูุฏ ุจู ุนูุณู ุขู ุฎูููุฉ ุจุฑููุฉ ุชููุฆุฉ'\n"
        "What we removed: ุฌูุงูุฉ (exaggeration), ุงููุนุธู (exaggeration), ุญูุธู ุงููู (prayer), ุฎุงูุตุฉ (exaggeration)\n"
        "What we kept: ุงูููู (simple title)\n\n"
        "Example 2 - KEEPING official 'ุตุงุญุจ ุงูุณูู ุงููููู' because it's OFFICIAL:\n"
        "โ BEFORE: 'ุงุณุชูุจู ุตุงุญุจ ุงูุณูู ุงููููู ุงูุฃููุฑ ุณููุงู ุจู ุญูุฏ ุขู ุฎูููุฉ ููู ุงูุนูุฏ ุฑุฆูุณ ูุฌูุณ ุงููุฒุฑุงุก ุญูุธู ุงููู'\n"
        "โ AFTER:  'ุงุณุชูุจู ุตุงุญุจ ุงูุณูู ุงููููู ุงูุฃููุฑ ุณููุงู ุจู ุญูุฏ ุขู ุฎูููุฉ ููู ุงูุนูุฏ ุฑุฆูุณ ูุฌูุณ ุงููุฒุฑุงุก'\n"
        "What we removed: ุญูุธู ุงููู (prayer phrase only!)\n"
        "What we kept: ุตุงุญุจ ุงูุณูู ุงููููู (OFFICIAL TITLE - DO NOT TOUCH!), ุงูุฃููุฑ, ููู ุงูุนูุฏ, ุฑุฆูุณ ูุฌูุณ ุงููุฒุฑุงุก\n"
        "โ๏ธ CRITICAL: We did NOT remove 'ุตุงุญุจ ุงูุณูู ุงููููู' because it is an OFFICIAL STATE TITLE!\n\n"
        "Example 3 - KEEPING official 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' because it's OFFICIAL:\n"
        "โ BEFORE: 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู ุงูููู ุณููุงู ุจู ุนุจุฏุงูุนุฒูุฒ ุขู ุณุนูุฏ ุญูุธู ุงููู ุฃูุฏู ุงููู'\n"
        "โ AFTER:  'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู ุงูููู ุณููุงู ุจู ุนุจุฏุงูุนุฒูุฒ ุขู ุณุนูุฏ'\n"
        "What we removed: ุญูุธู ุงููู (prayer), ุฃูุฏู ุงููู (prayer)\n"
        "What we kept: ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู (OFFICIAL SAUDI KING TITLE - NEVER REMOVE!), ุงูููู\n"
        "โ๏ธ CRITICAL: We did NOT remove 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' because it is the OFFICIAL TITLE of Saudi King!\n\n"
        "Example 4 - What happens when we see 'ุฌูุงูุฉ' vs 'ุตุงุญุจ ุงูุณูู ุงููููู':\n"
        "โ WRONG:  'ุฌูุงูุฉ ุงูููู' โ 'ุฌูุงูุฉ ุงูููู' (keeping exaggeration)\n"
        "โ RIGHT:  'ุฌูุงูุฉ ุงูููู' โ 'ุงูููู' (removed exaggeration)\n"
        "โ WRONG:  'ุตุงุญุจ ุงูุณูู ุงููููู ุงูุฃููุฑ' โ 'ุงูุฃููุฑ' (removed official title!)\n"
        "โ RIGHT:  'ุตุงุญุจ ุงูุณูู ุงููููู ุงูุฃููุฑ' โ 'ุตุงุญุจ ุงูุณูู ุงููููู ุงูุฃููุฑ' (kept official title!)\n\n"
        "๐ด FINAL WARNING:\n"
        "If you remove 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' or 'ุตุงุญุจ ุงูุณูู ุงููููู', you have FAILED!\n"
        "These are OFFICIAL STATE TITLES, not exaggeration!\n\n"
        "IMPORTANT: When replacing exaggerated titles, preserve 'ุงู' (definite article):\n"
        "โ CORRECT: 'ุงูุณูุทุงู' (with ุงู), 'ุงูููู' (with ุงู)\n"
        "โ WRONG: 'ุณูุทุงู' (without ุงู), 'ููู' (without ุงู)\n\n"
        "STEP-BY-STEP PROCESS:\n"
        "1. IMPORTANT: DO NOT modify any text inside quotation marks (\"...\", ยซ...ยป, \"...\")!\n"
        "   Quoted text must remain EXACTLY as it appears, including any honorifics or titles.\n"
        "   Example: If someone said \"ุฌูุงูุฉ ุงูููู ุงููุนุธู\" in quotes, keep it unchanged!\n"
        "2. Scan the entire article for ALL prohibited phrases listed in the guidelines (outside quotes).\n"
        "3. Replace each prohibited phrase with its EXACT specified replacement, preserving ุงู ุงูุชุนุฑูู when required.\n"
        "4. Double-check that titles like 'ุงูุณูุทุงู' and 'ุงูููู' always include ุงู ุงูุชุนุฑูู.\n"
        "5. Remove all prayer phrases (ุญูุธู ุงููู, ุฑุนุงู ุงููู, etc.) completely (outside quotes).\n"
        "6. Rewrite the article according to UNA editorial style.\n"
        "6. CRITICAL REQUIREMENT - OUTPUT FORMAT WITH TITLE (MANDATORY):\n"
        "   YOUR OUTPUT MUST START WITH THE ARTICLE TITLE/HEADLINE, THEN THE ARTICLE BODY.\n"
        "\n"
        "   โ๏ธ IMPORTANT: The article title is the FIRST LINE of the article (before the city/date line).\n"
        "   Example: 'ุฌูุงูุฉู ุงูุณูุทุงู ุงููุนุธู ูุฑุฆูุณ ุงููุฒุฑุงุก ุงูุฅุณุจุงูู ูุดูุฏุงู ุชูููุน ุงุชูุงููุฉ ู6 ูุฐูุฑุงุช ุชูุงูู'\n"
        "   This is the TITLE/HEADLINE - you MUST process it and return it as the FIRST LINE of your output!\n"
        "\n"
        "   PROCESSING THE TITLE:\n"
        "   - Apply the same honorific removal rules to the title\n"
        "   - Remove exaggerations like 'ุฌูุงูุฉ', 'ุงููุนุธู', 'ุญูุธู ุงููู'\n"
        "   - Keep official titles like 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู', 'ุตุงุญุจ ุงูุณูู ุงููููู'\n"
        "   - Make the title concise and neutral\n"
        "   Example transformation:\n"
        "   โ BEFORE: 'ุฌูุงูุฉู ุงูุณูุทุงู ุงููุนุธู ูุฑุฆูุณ ุงููุฒุฑุงุก ุงูุฅุณุจุงูู ูุดูุฏุงู ุชูููุน ุงุชูุงููุฉ ู6 ูุฐูุฑุงุช ุชูุงูู'\n"
        "   โ AFTER:  'ุงูุณูุทุงู ูุฑุฆูุณ ุงููุฒุฑุงุก ุงูุฅุณุจุงูู ูุดูุฏุงู ุชูููุน ุงุชูุงููุฉ ู6 ูุฐูุฑุงุช ุชูุงูู'\n"
        "\n"
        "7. PARAGRAPH DIVISION (MANDATORY) - THIS IS ABSOLUTELY CRITICAL:\n"
        "   ๐จ๐จ๐จ YOU MUST PRESERVE THE PARAGRAPH STRUCTURE! ๐จ๐จ๐จ\n"
        "\n"
        "   โ๏ธ CRITICAL RULE: The input article already has paragraphs separated by blank lines (\\n\\n).\n"
        "   You MUST maintain this paragraph structure in your output!\n"
        "\n"
        "   DO NOT merge all paragraphs into one continuous text!\n"
        "   DO NOT rewrite the article as a single long paragraph!\n"
        "\n"
        "   REQUIRED FORMAT:\n"
        "   - Each paragraph from the input should remain a separate paragraph in the output\n"
        "   - Separate EVERY paragraph with exactly TWO newlines (\\n\\n) to create blank lines\n"
        "   - Each paragraph should be 2-4 sentences focusing on ONE main idea\n"
        "   - For SHORT news: 1 paragraph only (title + body + closing)\n"
        "   - For LONG news with multiple topics: 2-4 paragraphs maximum\n"
        "\n"
        "   PARAGRAPH STRUCTURE (preserve from input):\n"
        "   โข Paragraph 1: Title/Headline\n"
        "   โข [BLANK LINE]\n"
        "   โข Paragraph 2: Opening with city/date and main announcement\n"
        "   โข [BLANK LINE]\n"
        "   โข Paragraph 3: Additional details or context\n"
        "   โข [BLANK LINE]\n"
        "   โข Paragraph 4: More specific information\n"
        "   โข [BLANK LINE]\n"
        "   โข Paragraph 5: Supporting details\n"
        "   โข [BLANK LINE]\n"
        "   โข Paragraph 6: More information\n"
        "   โข [BLANK LINE]\n"
        "   โข Final line: Closing tag '(ุงูุชูู)' or source tag 'ุงูุนููุงููุฉ/' on its OWN separate line\n"
        "\n"
        "   โ๏ธ CRITICAL: If the input article ends with 'ุงูุนููุงููุฉ/' or similar source tag,\n"
        "   keep it on a SEPARATE final line after a blank line!\n"
        "\n"
        "   ๐ด REAL-WORLD COMPLETE EXAMPLE (EXACTLY HOW OUTPUT SHOULD LOOK):\n"
        "\n"
        "   ุงูุณูุทุงู ูุฑุฆูุณ ุงููุฒุฑุงุก ุงูุฅุณุจุงูู ูุดูุฏุงู ุชูููุน ุงุชูุงููุฉ ู6 ูุฐูุฑุงุช ุชูุงูู\n"
        "\n"
        "   ูุฏุฑูุฏ ูู 5 ููููุจุฑ (ูููุง/ุงูุนููุงููุฉ) - ุดูุฏ ุงูุณูุทุงู ููุซู ุจู ุทุงุฑู ูุฑุฆูุณ ุงููุฒุฑุงุก ุงูุฅุณุจุงูู ุจูุฏุฑู ุณุงูุดูุซ ุงูููู ูู ูุตุฑ ููููููุง ุจูุฏุฑูุฏ ูุฑุงุณู ุงูุชูููุน ุนูู ุงุชูุงููุฉ ู6 ูุฐูุฑุงุช ุชูุงูู ุจูู ุงูุจูุฏูู ุงูุตุฏูููู ุดููุช ุงูุนุฏูุฏ ูู ุงููุฌุงูุงุชุ ูุฐูู ูู ุฅุทุงุฑ ุฒูุงุฑุฉ ุฏููุฉ ูููู ุจูุง ุงูุณูุทุงู ุฅูู ููููุฉ ุฅุณุจุงููุง.\n"
        "\n"
        "   ุชูุซูุช ุงูุงุชูุงููุฉ ูู ุงูุฅุนูุงุก ุงููุชุจุงุฏู ูู ุงูุชุฃุดูุฑุงุช ูุญุงููู ุฌูุงุฒุงุช ุงูุณูุฑ ุงูุฏุจูููุงุณูุฉ ูุงูุฎุงุตุฉ ูุงูุฎุฏูุฉ ุจูู ุณูุทูุฉ ุนููุงู ูููููุฉ ุฅุณุจุงููุง.\n"
        "\n"
        "   ุดููุช ูุฐูุฑุงุช ุงูุชูุงูู ูุฌุงูุงุช ุงูุซูุงูุฉ ูุงูุฑูุงุถุฉุ ูุชุฑููุฌ ุงูุงุณุชุซูุงุฑุ ูุงููุฌุงูุงุช ุงูุฒุฑุงุนูุฉ ูุงูุญููุงููุฉ ูุงูุณูููุฉ ูุงูุฃูู ุงูุบุฐุงุฆูุ ูุฅุฏุงุฑุฉ ูุญูุงูุฉ ููุงุฑุฏ ุงูููุงูุ ูุงูุทุงูุฉ ุงููุธููุฉุ ูุงูููู ูุงูุจููุฉ ุงูุฃุณุงุณูุฉ.\n"
        "\n"
        "   ููุน ููุงุจุฉ ุนู ุญูููุฉ ุณูุทูุฉ ุนููุงู ูู ูู ูุฒูุฑ ุงูุฎุงุฑุฌูุฉ ุจุฏุฑ ุจู ุญูุฏ ุงูุจูุณุนูุฏูุ ููุฒูุฑ ุงูุชุฌุงุฑุฉ ูุงูุตูุงุนุฉ ูุชุฑููุฌ ุงูุงุณุชุซูุงุฑ ููุณ ุจู ูุญูุฏ ุงูููุณูุ ููุฒูุฑ ุงูุทุงูุฉ ูุงููุนุงุฏู ุณุงูู ุจู ูุงุตุฑ ุงูุนููู.\n"
        "\n"
        "   ูุนู ุญูููุฉ ููููุฉ ุฅุณุจุงููุง ูู ูู ูุฒูุฑ ุงูุดุคูู ุงูุฎุงุฑุฌูุฉ ูุงูุงุชุญุงุฏ ุงูุฃูุฑูุจู ูุงูุชุนุงูู ุฎูุณูู ูุงูููู ุฃูุจุงุฑูุณุ ููุฒูุฑ ุงูุงูุชุตุงุฏ ูุงูุชุฌุงุฑุฉ ูุงูุดุฑูุงุช ูุงุฑููุณ ูููุฑุจูุ ููุฒูุฑ ุงูุฒุฑุงุนุฉ ูุตูุฏ ุงูุฃุณูุงู ูุงูุบุฐุงุก ูููุณ ุจูุงูุงุณ.\n"
        "\n"
        "   (ุงูุชูู)\n"
        "\n"
        "   โ๏ธ IMPORTANT NOTES:\n"
        "   - Each paragraph is on its own line, with a BLANK LINE between paragraphs!\n"
        "   - The closing tag '(ุงูุชูู)' or 'ุงูุนููุงููุฉ/' is on a SEPARATE line at the end!\n"
        "   - This is NOT one continuous block of text!\n"
        "\n"
        "8. Return ONLY the final revised news article in Arabic with THE TITLE FIRST, then PROPERLY SEPARATED PARAGRAPHS. No analysis or commentary.\n\n"
        "โ๏ธโ๏ธโ๏ธ FINAL REMINDER - READ THIS BEFORE OUTPUTTING โ๏ธโ๏ธโ๏ธ\n"
        "๐จ YOUR OUTPUT MUST HAVE MULTIPLE SEPARATE PARAGRAPHS WITH BLANK LINES BETWEEN THEM! ๐จ\n"
        "\n"
        "Required structure:\n"
        "1. Line 1: PROCESSED ARTICLE TITLE (with honorifics removed)\n"
        "2. Line 2: BLANK LINE (\\n\\n)\n"
        "3. Line 3: First paragraph (opening with city/date)\n"
        "4. Line 4: BLANK LINE (\\n\\n)\n"
        "5. Line 5: Second paragraph\n"
        "6. Line 6: BLANK LINE (\\n\\n)\n"
        "7. Line 7: Third paragraph\n"
        "8. ...and so on for ALL paragraphs\n"
        "\n"
        "โ WRONG (everything in one block):\n"
        "ุงูุนููุงู\\n\\nูุฏุฑูุฏ ูู 5 ููููุจุฑ - ุดูุฏ ุงูุณูุทุงู... ุชูุซูุช ุงูุงุชูุงููุฉ... ุดููุช ูุฐูุฑุงุช... ููุน ููุงุจุฉ... ูุนู ุญูููุฉ...\n"
        "\n"
        "โ CORRECT (separate paragraphs with blank lines):\n"
        "ุงูุนููุงู\\n\\nูุฏุฑูุฏ ูู 5 ููููุจุฑ - ุดูุฏ ุงูุณูุทุงู...\\n\\nุชูุซูุช ุงูุงุชูุงููุฉ...\\n\\nุดููุช ูุฐูุฑุงุช...\\n\\nููุน ููุงุจุฉ...\\n\\nูุนู ุญูููุฉ...\\n\\n(ุงูุชูู)\n"
        "\n"
        "โ๏ธ IMPORTANT: The closing tag '(ุงูุชูู)' or 'ุงูุนููุงููุฉ/' must be on a SEPARATE final line!\n"
        "\n"
        "If you do NOT include the title first โ YOU FAILED!\n"
        "If you merge paragraphs into one continuous text โ YOU FAILED!\n"
        "If you do NOT have blank lines between EVERY paragraph โ YOU FAILED!\n"
    )

    return [
        {
            "role": "system",
            "content": (
                "You are an Arabic news processor for UNA (Union of News Agencies).\n\n"
                "๐ด๐ด๐ด ุงููุงุนุฏุฉ ุงูุฃุณุงุณูุฉ: ูุง ุชูุนูุฏ ุตูุงุบุฉ ุงูุฎุจุฑ! ๐ด๐ด๐ด\n"
                "ุฃูุช ูุณุช ูุงุชุจุงูุ ุฃูุช ููุนุงูุฌ ูุตูุต. ูููุชู ุชุทุจูู ุชุนุฏููุงุช ูุญุฏุฏุฉ ููุท:\n"
                "1. ุฅุถุงูุฉ ุงูุฌูุณูุฉ ูู ุงูุนููุงู\n"
                "2. ุชูุณูู ุณุทุฑ ุงููุฏููุฉ ูุงูููุงูุฉ\n"
                "3. ุฅุฒุงูุฉ ุงูุฃููุงุจ ุงููุจุงูุบ ูููุง\n"
                "4. ุฅุถุงูุฉ (ุงูุชูู)\n"
                "5. ุชุตุญูุญ ุงูุฃุฎุทุงุก ุงูุฅููุงุฆูุฉ\n\n"
                "โ ููููุน: ุฅุนุงุฏุฉ ุงูุตูุงุบุฉุ ุฅุถุงูุฉ ูุนูููุงุชุ ุชุบููุฑ ุงููููุงุชุ ุงูุญุดู\n\n"
                "CONTENT VALIDATION - REJECT INAPPROPRIATE OR RANDOM TEXT:\n"
                "Before processing any text, you MUST validate that it is a legitimate news article:\n"
                "1. REJECT immediately if the text is:\n"
                "   - Random, meaningless, or nonsensical text\n"
                "   - Inappropriate, offensive, or harmful content\n"
                "   - Not a news article (e.g., spam, advertisements, personal messages)\n"
                "   - Contains only symbols, numbers without context, or gibberish\n"
                "   - Clearly not related to news or journalism\n"
                "2. If you reject the text, respond ONLY with: 'ERROR: ุงููุต ุงูููุฏู ุบูุฑ ููุงุณุจ ุฃู ุบูุฑ ุตุงูุญ ูููุนุงูุฌุฉ. ูุฑุฌู ุชูุฏูู ุฎุจุฑ ุตุญูุญ.'\n"
                "3. Only proceed with editing if the text is a legitimate, coherent news article.\n\n"
                "โ๏ธโ๏ธโ๏ธ CRITICAL DISTINCTION: OFFICIAL STATE TITLES vs EXAGGERATION โ๏ธโ๏ธโ๏ธ\n\n"
                "๐ด ABSOLUTE RULE YOU MUST UNDERSTAND:\n"
                "Some phrases are OFFICIAL STATE TITLES (like job titles) - these are NOT exaggeration!\n"
                "Other phrases are EXAGGERATED PRAISE - these must be removed!\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "โ PRESERVE THESE - OFFICIAL STATE TITLES (NEVER REMOVE!):\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "1. โ 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' - OFFICIAL title of Saudi King\n"
                "   This is NOT exaggeration! It's like saying 'President' or 'Prime Minister'!\n"
                "   โ๏ธ NEVER EVER remove this phrase! It's his official state designation!\n\n"
                "2. โ 'ุตุงุญุจ ุงูุณูู ุงููููู' - OFFICIAL Royal Highness title\n"
                "   This is NOT exaggeration! It's the government-recognized protocol title!\n"
                "   โ๏ธ NEVER EVER remove this phrase! It's their official rank in the state!\n\n"
                "3. โ 'ููู ุงูุนูุฏ' - Crown Prince (official position)\n"
                "4. โ 'ุฑุฆูุณ ูุฌูุณ ุงููุฒุฑุงุก' - Prime Minister (official position)\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "โ REMOVE THESE - EXAGGERATED PRAISE (NOT OFFICIAL!):\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "1. โ 'ุฌูุงูุฉ ุงูููู ุงููุนุธู' โ โ 'ุงูููู' (this IS exaggeration!)\n"
                "2. โ 'ุฌูุงูุฉ ุงูููู' โ โ 'ุงูููู'\n"
                "3. โ 'ุญุถุฑุฉ ุตุงุญุจ ุงูุฌูุงูุฉ ุงูููู' โ โ 'ุงูููู'\n"
                "4. โ 'ุตุงุญุจ ุงูุฌูุงูุฉ ุงูุณูุทุงู' โ โ 'ุงูุณูุทุงู'\n"
                "5. โ 'ูุฎุงูุฉ ุงูุฑุฆูุณ' โ โ 'ุงูุฑุฆูุณ'\n"
                "6. โ Prayer phrases: 'ุญูุธู ุงููู', 'ุฃูุฏู ุงููู', 'ุฑุนุงู ุงููู' โ DELETE\n"
                "7. โ Exaggeration words: 'ุงููุนุธู', 'ุงูุฌููู', 'ุฎุงูุต' โ DELETE\n\n"
                "๐ KEY DIFFERENCE:\n"
                "โข 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' = Like saying 'President Obama' โ KEEP!\n"
                "โข 'ุตุงุญุจ ุงูุณูู ุงููููู' = Like saying 'His Royal Highness' โ KEEP!\n"
                "โข 'ุฌูุงูุฉ ุงูููู ุงููุนุธู' = Like saying 'His Glorious Majesty' โ REMOVE!\n"
                "โข 'ุญูุธู ุงููู' = Prayer/blessing โ REMOVE!\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "๐ MANDATORY EXAMPLES - FOLLOW THESE EXACTLY:\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
                "Example 1 - Remove exaggeration, keep simple title:\n"
                "Original: 'ุจุนุซ ุฌูุงูุฉ ุงูููู ุงููุนุธู ุนุจุฏ ุงููู ุงูุซุงูู ุงุจู ุงูุญุณูู ุญูุธู ุงููู ุจุฑููุฉ ุชููุฆุฉ ุฎุงูุตุฉ'\n"
                "After: 'ุจุนุซ ุงูููู ุนุจุฏ ุงููู ุงูุซุงูู ุงุจู ุงูุญุณูู ุจุฑููุฉ ุชููุฆุฉ'\n"
                "Removed: ุฌูุงูุฉ, ุงููุนุธู, ุญูุธู ุงููู, ุฎุงูุตุฉ\n"
                "Kept: ุงูููู\n\n"
                "Example 2 - KEEP 'ุตุงุญุจ ุงูุณูู ุงููููู' (OFFICIAL TITLE!):\n"
                "Original: 'ุงุณุชูุจู ุตุงุญุจ ุงูุณูู ุงููููู ุงูุฃููุฑ ุณููุงู ุจู ุญูุฏ ุขู ุฎูููุฉ ููู ุงูุนูุฏ ุฑุฆูุณ ูุฌูุณ ุงููุฒุฑุงุก ุญูุธู ุงููู'\n"
                "After: 'ุงุณุชูุจู ุตุงุญุจ ุงูุณูู ุงููููู ุงูุฃููุฑ ุณููุงู ุจู ุญูุฏ ุขู ุฎูููุฉ ููู ุงูุนูุฏ ุฑุฆูุณ ูุฌูุณ ุงููุฒุฑุงุก'\n"
                "Removed: ุญูุธู ุงููู ONLY!\n"
                "Kept: ุตุงุญุจ ุงูุณูู ุงููููู (OFFICIAL!), ุงูุฃููุฑ, ููู ุงูุนูุฏ, ุฑุฆูุณ ูุฌูุณ ุงููุฒุฑุงุก\n"
                "โ๏ธ Notice: We did NOT remove 'ุตุงุญุจ ุงูุณูู ุงููููู' - it's an OFFICIAL title!\n\n"
                "Example 3 - KEEP 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' (OFFICIAL TITLE!):\n"
                "Original: 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู ุงูููู ุณููุงู ุจู ุนุจุฏุงูุนุฒูุฒ ุขู ุณุนูุฏ ุญูุธู ุงููู ุฃูุฏู ุงููู'\n"
                "After: 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู ุงูููู ุณููุงู ุจู ุนุจุฏุงูุนุฒูุฒ ุขู ุณุนูุฏ'\n"
                "Removed: ุญูุธู ุงููู, ุฃูุฏู ุงููู ONLY!\n"
                "Kept: ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู (OFFICIAL SAUDI TITLE!), ุงูููู\n"
                "โ๏ธ Notice: We did NOT remove 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' - it's the OFFICIAL title!\n\n"
                "Example 4 - Understanding the difference:\n"
                "โ WRONG: 'ุตุงุญุจ ุงูุณูู ุงููููู ุงูุฃููุฑ' โ 'ุงูุฃููุฑ' (you removed official title!)\n"
                "โ RIGHT: 'ุตุงุญุจ ุงูุณูู ุงููููู ุงูุฃููุฑ' โ 'ุตุงุญุจ ุงูุณูู ุงููููู ุงูุฃููุฑ' (kept it!)\n"
                "โ WRONG: 'ุฌูุงูุฉ ุงูููู' โ 'ุฌูุงูุฉ ุงูููู' (you kept exaggeration!)\n"
                "โ RIGHT: 'ุฌูุงูุฉ ุงูููู' โ 'ุงูููู' (removed exaggeration!)\n\n"
                "๐ด If you remove 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' or 'ุตุงุญุจ ุงูุณูู ุงููููู', YOU FAILED!\n\n"
                "IMPORTANT RULE: Always preserve 'ุงู' (definite article) when simplifying titles:\n"
                "โ CORRECT: 'ุงูุณูุทุงู' (with ุงู), 'ุงูููู' (with ุงู)\n"
                "โ WRONG: 'ุณูุทุงู' (without ุงู), 'ููู' (without ุงู)\n\n"
                "EDITORIAL STYLE GUIDELINES:\n"
                "1. Use only modern formal Arabic language.\n"
                "2. Avoid emotional and exaggerated expressions.\n"
                "3. Maintain objectivity and balance in all headlines and texts.\n"
                "4. Headlines must be concise and neutral (without exclamation marks or promotional words).\n"
                "5. Do not add personal analyses or conclusions unless from an official explicit source.\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "๐ด ูุงุนุฏุฉ ุงูุฌูุณูุฉ ูู ุงูุนูุงููู (ุฅูุฒุงููุฉ!) ๐ด\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "ุนูุฏ ุฐูุฑ ุฃู ูุณุคูู ุฃู ูุฒุงุฑุฉ ูู ุงูุนููุงูุ ูุฌุจ ุฅุถุงูุฉ ุงูุฌูุณูุฉ:\n"
                "โข ุฑุฆูุณ ุงููุฒุฑุงุก โ ุฑุฆูุณ ุงููุฒุฑุงุก ุงูุนุฑุงูู/ุงูุณุนูุฏู/ุงููุตุฑู\n"
                "โข ุงูููู โ ุงูููู ุงูุณุนูุฏู/ุงูุฃุฑุฏูู/ุงููุบุฑุจู\n"
                "โข ุงูุฎุงุฑุฌูุฉ โ ุงูุฎุงุฑุฌูุฉ ุงูุณุนูุฏูุฉ/ุงููุตุฑูุฉ/ุงูุฅูุงุฑุงุชูุฉ\n"
                "โข ูุฒุงุฑุฉ ุงูุตุญุฉ โ ูุฒุงุฑุฉ ุงูุตุญุฉ ุงูุณุนูุฏูุฉ\n"
                "โข ูุฒูุฑ ุงูุณูุงุญุฉ โ ูุฒูุฑ ุงูุณูุงุญุฉ ุงูุณุนูุฏู\n\n"
                "โ๏ธ ุงุณุชุซูุงุก: 'ูุฒุงุฑุฉ ุงูุญุฌ ูุงูุนูุฑุฉ' ูุง ุชุญุชุงุฌ ุฌูุณูุฉ (ูุญูุฏุฉ ูู ุงูุนุงูู)\n\n"
                "ููู ุชุญุฏุฏ ุงูุฌูุณูุฉ:\n"
                "โข ูุงุน=ุนุฑุงูู | ูุงุณ=ุณุนูุฏู | ูุงู=ุฅูุงุฑุงุชู | ููููุง=ูููุชู | ุจูุง=ุจุญุฑููู\n"
                "โข ุจุบุฏุงุฏ=ุนุฑุงูู | ุงูุฑูุงุถ=ุณุนูุฏู | ุงููุงูุฑุฉ=ูุตุฑู\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "๐ด๐ด๐ด ูุงุนุฏุฉ ุงูุงุฎุชุตุงุฑ - ุงูุฃูู! (CRITICAL!) ๐ด๐ด๐ด\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "โ๏ธ ุงูุฎุจุฑ = ุนููุงู + ููุฑุฉ ูุงุญุฏุฉ ููุท + (ุงูุชูู)\n"
                "โ๏ธ ุงูุญุฏ ุงูุฃูุตู: 3-4 ุฃุณุทุฑ!\n"
                "โ๏ธ ูุง ุชุถู ูุนูููุงุช ุบูุฑ ููุฌูุฏุฉ ูู ุงูุฃุตู!\n"
                "โ๏ธ ูุง ุชูุฑุฑ ุงุณู ุงููุณุคูู!\n"
                "โ๏ธ ูุง ุชุถู 'ูุฃูุถุญ' ุฃู 'ูุฃูุฏ ุฃูููุฉ' ุฃู 'ุฌุงุก ุฐูู'!\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "๐ด๐ด๐ด ููุงุนุฏ ุฅูุฒุงููุฉ - ูุฌุจ ุชุทุจูููุง ุฌููุนุงู! ๐ด๐ด๐ด\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "โ ุงููุงุนุฏุฉ 1: ุงูุนููุงู ูู ุณุทุฑ ูุณุชูู (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 2: ูููุฉ (ุงูุชูู) ูู ุณุทุฑ ูุณุชูู (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 3: ุฐูุฑ ุงุณู ุงูููุงูุฉ ุจุนุฏ (ูููุง/) - ูุซุงู: (ูููุง/ูุงุน) ุฃู (ูููุง/ุงูุบุฏ) (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 4: ุงูุนููุงู ูุง ูุชุฌุงูุฒ 12 ูููุฉ (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 5: ุงูููุฑุฉ ูุง ุชุฒูุฏ ุนู 50 ูููุฉ (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 6: ุงุณุชุจุฏุงู 'ูุฑุงุณููุง' ุจู 'ูุฑุงุณู [ุงูููุงูุฉ ุงููุตุฏุฑ]' - ููุณ ูููุง! (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 7: ุงูุชูููุน ูู ุงูุฃูุนุงู ุงูุฅุนูุงููุฉ - ููููุน ุชูุฑุงุฑ ููุณ ุงููุนู (ุฅูุฒุงูู)\n"
                "   ุงูุฃูุนุงู: ูุงูุ ุฐูุฑุ ุฃูุถุญุ ุฃูุฏุ ุดุฏูุฏุ ุจูููุ ุฃุดุงุฑุ ุฃูุงุฏุ ุฃุนููุ ูุดูุ ููุชุ ุตุฑูุญุ ุฃุจุฑุฒ\n"
                "โ ุงููุงุนุฏุฉ 8: ุชูุงุณู ุงูุฌูู ุจุฃุฏูุงุช ุงูุฑุจุท ุงูููุงุณุจุฉ (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 9: ูู ุฃุฎุจุงุฑ ููุณุทูู: ุงุณุชุฎุฏู 'ุงุณุชุดูุงุฏ' ุจุฏูุงู ูู 'ููุชู/ูุตุฑุน/ููุช' (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 10: ุงูุชุงุฑูุฎ ุจุงููููุงุฏู ููุท: ุงูุฃุญุฏ 21 ุฏูุณูุจุฑ 2025ู (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 11: ููููุน ุงูุตูุงุช ุงูุชูุฑูุฑูุฉ ุจุฏูู ุฏููู: ุถุฎูุ ุชุงุฑูุฎูุ ุบูุฑ ูุณุจูู (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 12: ุชุฌูุจ ุงูุฅูุฑุงุท ูู ุงูุฃููุงุณ (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 13: ููููุน ุงูุชูุฑุงุฑ ุบูุฑ ุงููุจุฑุฑ (ุฅูุฒุงูู)\n"
                "โ ุงููุงุนุฏุฉ 14: ุงูุงูุชูุงู ุจุนูุงูุงุช ุงูุชุฑููู (ุงูููุงุตู ูุงูููุงุท) (ุฅูุฒุงูู)\n\n"
                "๐จ ุชุญุฐูุฑ: ุนุฏู ุชุทุจูู ุฃู ูุงุนุฏุฉ = ูุดู! ๐จ\n\n"
                "GENERAL EDITING INSTRUCTIONS:\n"
                "1. โ DO NOT rewrite the news - keep the original text!\n"
                "2. Only add nationality to titles in headlines\n"
                "3. Only format the city/agency line\n"
                "4. Only remove exaggerated honorifics\n"
                "5. Only fix spelling errors\n"
                "6. Add (ุงูุชูู) at the end\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "๐ STEP-BY-STEP EDITING PROCESS:\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
                "Step 1 - Scan for OFFICIAL TITLES to PRESERVE:\n"
                "   โ Do you see 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู'? โ KEEP IT!\n"
                "   โ Do you see 'ุตุงุญุจ ุงูุณูู ุงููููู'? โ KEEP IT!\n"
                "   โ Do you see 'ููู ุงูุนูุฏ'? โ KEEP IT!\n"
                "   โ Do you see 'ุฑุฆูุณ ูุฌูุณ ุงููุฒุฑุงุก'? โ KEEP IT!\n"
                "   These are OFFICIAL STATE TITLES - like job titles - NOT exaggeration!\n\n"
                "Step 2 - Scan for EXAGGERATION to REMOVE:\n"
                "   โ Do you see 'ุฌูุงูุฉ ุงูููู'? โ Change to 'ุงูููู'\n"
                "   โ Do you see 'ุตุงุญุจ ุงูุฌูุงูุฉ ุงูุณูุทุงู'? โ Change to 'ุงูุณูุทุงู'\n"
                "   โ Do you see 'ุญูุธู ุงููู' or 'ุฃูุฏู ุงููู'? โ DELETE completely\n"
                "   โ Do you see 'ุงููุนุธู', 'ุงูุฌููู', 'ุฎุงูุต'? โ DELETE\n"
                "   These are EXAGGERATED PRAISE - not official titles!\n\n"
                "Step 3 - Apply changes CAREFULLY (but preserve quoted text):\n"
                "   ๐จ CRITICAL: DO NOT modify any text inside quotation marks!\n"
                "   Text within quotes (\"...\", ยซ...ยป, \"...\") must remain UNCHANGED!\n"
                "   Example: \"ุฌูุงูุฉ ุงูููู ุงููุนุธู\" in quotes stays exactly as is!\n"
                "   \n"
                "   For non-quoted text:\n"
                "   โข NEVER remove: ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู, ุตุงุญุจ ุงูุณูู ุงููููู\n"
                "   โข ALWAYS remove: ุฌูุงูุฉ, ุตุงุญุจ ุงูุฌูุงูุฉ, ูุฎุงูุฉ\n"
                "   โข DELETE prayer phrases: ุญูุธู ุงููู, ุฃูุฏู ุงููู, ุฑุนุงู ุงููู\n"
                "   โข When simplifying, preserve ุงู: ุงูุณูุทุงู (not ุณูุทุงู), ุงูููู (not ููู)\n\n"
                "Step 4 - Final verification checklist:\n"
                "   โ Is 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู' still there (if it was in original)?\n"
                "   โ Is 'ุตุงุญุจ ุงูุณูู ุงููููู' still there (if it was in original)?\n"
                "   โ Are all prayer phrases ('ุญูุธู ุงููู', etc.) deleted?\n"
                "   โ Are all exaggerations ('ุฌูุงูุฉ', 'ุงููุนุธู', etc.) removed?\n"
                "   โ Is ุงู ุงูุชุนุฑูู preserved in simplified titles?\n\n"
                "Step 5 - Apply editorial style guidelines (objectivity, clarity, etc.).\n\n"
                "Step 6 - Rewrite the article according to UNA editorial style.\n\n"
                "8. MANDATORY OUTPUT FORMAT - TITLE FIRST, THEN SEPARATE PARAGRAPHS:\n"
                "   ๐จ๐จ๐จ CRITICAL: PRESERVE PARAGRAPH STRUCTURE WITH BLANK LINES! ๐จ๐จ๐จ\n"
                "\n"
                "   a) IDENTIFY THE TITLE: The title is the FIRST LINE of the input article (before city/date).\n"
                "      Example input title: 'ุฌูุงูุฉู ุงูุณูุทุงู ุงููุนุธู ูุฑุฆูุณ ุงููุฒุฑุงุก ุงูุฅุณุจุงูู ูุดูุฏุงู ุชูููุน ุงุชูุงููุฉ'\n"
                "\n"
                "   b) PROCESS THE TITLE: Apply honorific rules to clean the title:\n"
                "      - Remove: 'ุฌูุงูุฉ', 'ุงููุนุธู', 'ุญูุธู ุงููู', 'ุตุงุญุจ ุงูุฌูุงูุฉ'\n"
                "      - Keep: 'ุฎุงุฏู ุงูุญุฑููู ุงูุดุฑูููู', 'ุตุงุญุจ ุงูุณูู ุงููููู'\n"
                "      Example output title: 'ุงูุณูุทุงู ูุฑุฆูุณ ุงููุฒุฑุงุก ุงูุฅุณุจุงูู ูุดูุฏุงู ุชูููุน ุงุชูุงููุฉ'\n"
                "\n"
                "   c) OUTPUT FORMAT - MULTIPLE SEPARATE PARAGRAPHS:\n"
                "      Line 1: Processed title\n"
                "      Line 2: BLANK LINE (\\n\\n)\n"
                "      Line 3: First body paragraph (city/date + main news)\n"
                "      Line 4: BLANK LINE (\\n\\n)\n"
                "      Line 5: Second body paragraph\n"
                "      Line 6: BLANK LINE (\\n\\n)\n"
                "      Line 7: Third body paragraph\n"
                "      ...and so on with BLANK LINES between EVERY paragraph\n"
                "\n"
                "   d) PARAGRAPH REQUIREMENTS:\n"
                "      - DO NOT merge paragraphs into one continuous block!\n"
                "      - Each paragraph = 2-4 sentences on ONE topic\n"
                "      - Separate EVERY paragraph with \\n\\n (blank line)\n"
                "      - For SHORT news: 1 paragraph only! For LONG news: 2-4 paragraphs max\n"
                "      - The input article already has paragraph breaks - PRESERVE THEM!\n"
                "      - The closing tag '(ุงูุชูู)' or 'ุงูุนููุงููุฉ/' must be on a SEPARATE final line!\n"
                "\n"
                "   e) COMPLETE REAL-WORLD EXAMPLE:\n"
                "      ุงูุณูุทุงู ูุฑุฆูุณ ุงููุฒุฑุงุก ุงูุฅุณุจุงูู ูุดูุฏุงู ุชูููุน ุงุชูุงููุฉ ู6 ูุฐูุฑุงุช ุชูุงูู\n"
                "      \n"
                "      ูุฏุฑูุฏ ูู 5 ููููุจุฑ (ูููุง/ุงูุนููุงููุฉ) - ุดูุฏ ุงูุณูุทุงู ููุซู ุจู ุทุงุฑู ูุฑุฆูุณ ุงููุฒุฑุงุก...\n"
                "      \n"
                "      ุชูุซูุช ุงูุงุชูุงููุฉ ูู ุงูุฅุนูุงุก ุงููุชุจุงุฏู ูู ุงูุชุฃุดูุฑุงุช...\n"
                "      \n"
                "      ุดููุช ูุฐูุฑุงุช ุงูุชูุงูู ูุฌุงูุงุช ุงูุซูุงูุฉ ูุงูุฑูุงุถุฉ...\n"
                "      \n"
                "      ููุน ููุงุจุฉ ุนู ุญูููุฉ ุณูุทูุฉ ุนููุงู ูู ูู ูุฒูุฑ ุงูุฎุงุฑุฌูุฉ...\n"
                "      \n"
                "      ูุนู ุญูููุฉ ููููุฉ ุฅุณุจุงููุง ูู ูู ูุฒูุฑ ุงูุดุคูู ุงูุฎุงุฑุฌูุฉ...\n"
                "      \n"
                "      (ุงูุชูู)\n"
                "      \n"
                "      โ๏ธ NOTE: The closing tag '(ุงูุชูู)' or source tag like 'ุงูุนููุงููุฉ/' must be on a SEPARATE final line!\n"
                "\n"
                "9. Deliver ONLY the final revised article in Arabic: TITLE first, then SEPARATE PARAGRAPHS with BLANK LINES between them; no analysis or explanations."
            ),
        },
        {"role": "user", "content": user_prompt},
    ]


def _split_into_paragraphs(text: str) -> str:
    """
    Post-process the AI output to ensure proper paragraph separation.
    This function intelligently splits text into paragraphs based on content patterns.
    """
    # If the text already has proper paragraph breaks, return as is
    if "\n\n" in text and text.count("\n\n") >= 3:
        return text

    # Remove any existing single newlines (but preserve double newlines if they exist)
    text = text.replace("\n\n", "<<<PARAGRAPH_BREAK>>>")
    text = text.replace("\n", " ")
    text = text.replace("<<<PARAGRAPH_BREAK>>>", "\n\n")

    # Step 1: Separate the title from the body
    # Look for city/agency patterns like "ุจุบุฏุงุฏ (ูููุง/ูุงุน)" or "ุงูุฑูุงุถ (ูููุง/ูุงุณ)"
    city_agency_pattern = r'^(.+?)\s+((?:ูุฏุฑูุฏ|ุงูููุงูุฉ|ุงูุฑูุงุถ|ุนููุงู|ุนูุงู|ุงููุงูุฑุฉ|ุฏูุดู|ุจุบุฏุงุฏ|ูุณูุท|ุงููููุช|ุงูุฏูุญุฉ|ุฃุจูุธุจู|ุฃุจู ุธุจู|ุจูุฑูุช|ุชููุณ|ุงูุฌุฒุงุฆุฑ|ุงูุฑุจุงุท|ุทุฑุงุจูุณ|ููุงูุดูุท|ุตูุนุงุก|ุงูุฎุฑุทูู)(?:\s+ูู\s+\d|\s*\(ูููุง))'
    match = re.search(city_agency_pattern, text)

    if match:
        # Extract title and body
        title = match.group(1).strip()
        body = text[match.start(2):].strip()
        # Make sure title doesn't end with the city name
        if not any(city in title[-20:] for city in ['ุจุบุฏุงุฏ', 'ุงูุฑูุงุถ', 'ุงููุงูุฑุฉ', 'ุฏูุดู', 'ุนูุงู', 'ูุณูุท']):
            text = f"{title}\n\n{body}"

    # Step 2: Split by common paragraph starters
    paragraph_starters = [
        r'([.ุ!])\s+(ูุฃุดุงุฏ)',
        r'([.ุ!])\s+(ูุฃูุฏ)',
        r'([.ุ!])\s+(ููุงู)',
        r'([.ุ!])\s+(ูุฃุถุงู)',
        r'([.ุ!])\s+(ุฌุงุก ุฐูู)',
        r'([.ุ!])\s+(ูุฌุงุก)',
        r'([.ุ!])\s+(ููุง)',
        r'([.ุ!])\s+(ูุดูุฏ)',
        r'([.ุ!])\s+(ูุดููุช)',
        r'([.ุ!])\s+(ูุชูุซููุช)',
        r'([.ุ!])\s+(ุชูุซูุช)',
        r'([.ุ!])\s+(ุดููุช)',
        r'([.ุ!])\s+(ูููุน)',
        r'([.ุ!])\s+(ูููุน)',
        r'([.ุ!])\s+(ููุน)',
        r'([.ุ!])\s+(ูุนู)',
        r'([.ุ!])\s+(ูู ุฌุงูุจู)',
        r'([.ุ!])\s+(ูู ุฌูุชู)',
        r'([.ุ!])\s+(ูู ุฌุงูุจูุง)',
        r'([.ุ!])\s+(ุจุฏูุฑู)',
    ]

    # Apply paragraph splitting
    for pattern in paragraph_starters:
        text = re.sub(pattern, r'\1\n\n\2', text)

    # Step 3: Ensure closing tags are on separate lines
    text = re.sub(r'([.ุ!])\s*(\(ุงูุชูู\))', r'\1\n\n\2', text)
    text = re.sub(r'([.ุ!])\s*(ุงูุนููุงููุฉ/)', r'\1\n\n\2', text)

    # Handle case where closing tag is at the end without punctuation
    text = re.sub(r'(\S)\s+(\(ุงูุชูู\))', r'\1\n\n\2', text)
    text = re.sub(r'(\S)\s+(ุงูุนููุงููุฉ/)', r'\1\n\n\2', text)

    # Step 4: Clean up any triple or more newlines
    while "\n\n\n" in text:
        text = text.replace("\n\n\n", "\n\n")

    return text.strip()


def _search_google_for_fact_check(query: str) -> str:
    """
    Search Google using SERP API to gather information for fact-checking.

    Args:
        query: The search query

    Returns:
        Formatted search results as a string
    """
    serpapi_key = settings.SERPAPI_KEY
    if not serpapi_key:
        # If no SERP API key, return empty results
        return "ูุง ุชูุฌุฏ ูุชุงุฆุฌ ุจุญุซ ูุชุงุญุฉ."

    try:
        # Remove quotes from the API key if present
        serpapi_key = serpapi_key.strip('"\'')

        params = {
            "q": query,
            "api_key": serpapi_key,
            "num": 5,  # Get top 5 results
            "hl": "ar",  # Arabic language
            "gl": "sa",  # Saudi Arabia region
        }

        search = GoogleSearch(params)
        results = search.get_dict()

        # Extract organic results
        organic_results = results.get("organic_results", [])

        if not organic_results:
            return "ูู ูุชู ุงูุนุซูุฑ ุนูู ูุชุงุฆุฌ ุจุญุซ."

        # Format results
        formatted_results = []
        for idx, result in enumerate(organic_results[:5], 1):
            title = result.get("title", "")
            snippet = result.get("snippet", "")
            formatted_results.append(f"{idx}. {title}\n   {snippet}")

        return "\n\n".join(formatted_results)

    except Exception as e:
        # If search fails, return error message
        return f"ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุงูุจุญุซ: {str(e)}"


def check_and_correct_text_between_hashtags(
    *,
    text: str,
    model: str = DEFAULT_COMPLETION_MODEL,
    full_context: str = None,
) -> str:
    """
    Extract text between ##text## markers and check/correct factual and linguistic errors using OpenAI.

    Args:
        text: The input text containing ##text## markers
        model: OpenAI model to use for correction
        full_context: Optional full context text to help with fact-checking

    Returns:
        The corrected text that was between the hashtags

    Raises:
        ValueError: If no text is found between ## markers
    """
    # Extract text between ##text##
    pattern = r'##(.+?)##'
    matches = re.findall(pattern, text, re.DOTALL)

    if not matches:
        raise ValueError("No text found between ## markers. Please use format: ##your text here##")

    # Use the first match if multiple exist
    text_to_check = matches[0].strip()

    if not text_to_check:
        raise ValueError("Empty text found between ## markers.")

    # Get context around the marked text for better understanding
    context_text = full_context if full_context else text

    # Search Google for fact-checking with better query
    # Build search query based on context
    search_query = text_to_check

    # Check if this is about a person with a title/position
    if "ูููุง" in context_text or "UNA" in context_text.upper():
        search_query = "ุงููุฏูุฑ ุงูุนุงู ุงุชุญุงุฏ ููุงูุงุช ุฃูุจุงุก ูููุง OIC UNA director general 2025"
    elif "ุงููุฏูุฑ" in context_text or "ุงูุฑุฆูุณ" in context_text or "ุงููุฒูุฑ" in context_text:
        # Extract organization/context from the full text
        search_query = f"{context_text[:200]} ูู ูู"
    else:
        search_query = f"{text_to_check} ุญูููุฉ ุชุญูู"

    search_results = _search_google_for_fact_check(search_query)

    client = _get_openai_client()

    # Build the prompt for factual and linguistic correction
    messages = [
        {
            "role": "system",
            "content": (
                "ุฃูุช ูุญุฑุฑ ุตุญูู ูุญุชุฑู ูุชุฎุตุต ูู ุงูุชุญูู ูู ุตุญุฉ ุงููุนูููุงุช ูุชุตุญูุญ ุงูุฃุฎุทุงุก ุงููุงูุนูุฉ.\n\n"
                "โ๏ธ ูููุชู ุงูุฑุฆูุณูุฉ: ุงูุชุญูู ูู ุตุญุฉ ุงููุนูููุงุช ุงููุงูุนูุฉ ูุชุตุญูุญูุง ุจุงุณุชุฎุฏุงู ูุชุงุฆุฌ ุงูุจุญุซ ุงูููุฏูุฉ\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "1. **ุงุณุชุฎุฏุงู ูุชุงุฆุฌ ุงูุจุญุซ (ุงูุฃููููุฉ ุงููุตูู):**\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
                "๐ด ุณูุชู ุชุฒููุฏู ุจูุชุงุฆุฌ ุจุญุซ ูู ุฌูุฌู ุนู ุงููุนูููุงุช ุงููุทููุจ ุงูุชุญูู ูููุง.\n"
                "ุงุณุชุฎุฏู ูุฐู ุงููุชุงุฆุฌ ููุชุญูู ูู ุตุญุฉ ุงููุนูููุงุช ูุชุตุญูุญูุง.\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "2. **ุงูุชุญูู ูู ุงููุนูููุงุช ุงูุฌุบุฑุงููุฉ (ููู ุฌุฏุงู):**\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
                "๐ด ูุงุนุฏุฉ ุญุงุณูุฉ: ุฅุฐุง ุฑุฃูุช ูููุฉ 'ุงูุนุงุตูุฉ' ุฃู 'ุนุงุตูุฉ'ุ ุชุญูู ููุฑุงู ูู ุตุญุฉ ุงุณู ุงููุฏููุฉ!\n\n"
                "ุนูุงุตู ุงูุฏูู ุงูุนุฑุจูุฉ ูุงูุฅุณูุงููุฉ (ูููุฑุฌุนูุฉ):\n"
                "โข ูุตุฑ โ ุงููุงูุฑุฉ (ููุณุช: ุงูุฅุณููุฏุฑูุฉุ ุงูุฌูุฒุฉุ ุฃุณูุงู)\n"
                "โข ุงูุณุนูุฏูุฉ โ ุงูุฑูุงุถ (ููุณุช: ุฌุฏุฉุ ููุฉุ ุงููุฏููุฉุ ุงูุทุงุฆู)\n"
                "โข ุงูุฅูุงุฑุงุช โ ุฃุจูุธุจู (ููุณุช: ุฏุจูุ ุงูุดุงุฑูุฉ)\n"
                "โข ุงููููุช โ ุงููููุช\n"
                "โข ุงูุจุญุฑูู โ ุงูููุงูุฉ\n"
                "โข ูุทุฑ โ ุงูุฏูุญุฉ\n"
                "โข ุนููุงู โ ูุณูุท\n"
                "โข ุงูุฃุฑุฏู โ ุนููุงู\n"
                "โข ูุจูุงู โ ุจูุฑูุช\n"
                "โข ุณูุฑูุง โ ุฏูุดู\n"
                "โข ุงูุนุฑุงู โ ุจุบุฏุงุฏ\n"
                "โข ุงูููู โ ุตูุนุงุก\n"
                "โข ููุณุทูู โ ุงููุฏุณ (ุฑุงู ุงููู ุฅุฏุงุฑูุงู)\n"
                "โข ุงูุณูุฏุงู โ ุงูุฎุฑุทูู\n"
                "โข ุงููุบุฑุจ โ ุงูุฑุจุงุท (ููุณุช: ุงูุฏุงุฑ ุงูุจูุถุงุก)\n"
                "โข ุงูุฌุฒุงุฆุฑ โ ุงูุฌุฒุงุฆุฑ\n"
                "โข ุชููุณ โ ุชููุณ\n"
                "โข ููุจูุง โ ุทุฑุงุจูุณ\n"
                "โข ููุฑูุชุงููุง โ ููุงูุดูุท\n"
                "โข ุงูุตููุงู โ ููุฏูุดู\n"
                "โข ุฌูุจูุชู โ ุฌูุจูุชู\n"
                "โข ุฌุฒุฑ ุงูููุฑ โ ููุฑููู\n\n"
                "๐ด ุฃูุซูุฉ ูุงูุนูุฉ ููุชุตุญูุญ:\n"
                "โ 'ูู ุงูุนุงุตูุฉ ุงูุทุงุฆู' โ โ 'ูู ุงูุฑูุงุถ' (ุงูุทุงุฆู ููุณุช ุงูุนุงุตูุฉ!)\n"
                "โ 'ูู ุงูุนุงุตูุฉ ุฌุฏุฉ' โ โ 'ูู ุงูุฑูุงุถ' (ุฌุฏุฉ ููุณุช ุงูุนุงุตูุฉ!)\n"
                "โ 'ุงูุนุงุตูุฉ ุงููุตุฑูุฉ ุงูุฌูุฒุฉ' โ โ 'ุงูุนุงุตูุฉ ุงููุตุฑูุฉ ุงููุงูุฑุฉ'\n"
                "โ 'ุนุงุตูุฉ ุงูุฅูุงุฑุงุช ุฏุจู' โ โ 'ุนุงุตูุฉ ุงูุฅูุงุฑุงุช ุฃุจูุธุจู'\n"
                "โ 'ุงูุนุงุตูุฉ ุงููุบุฑุจูุฉ ุงูุฏุงุฑ ุงูุจูุถุงุก' โ โ 'ุงูุนุงุตูุฉ ุงููุบุฑุจูุฉ ุงูุฑุจุงุท'\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "3. **ุงูุชุญูู ูู ุงูุฃุณูุงุก ูุงูููุงุตุจ (ููู ุฌุฏุงู!):**\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
                "๐ด ูุงุนุฏุฉ ุญุงุณูุฉ: ุฅุฐุง ุฑุฃูุช ุงุณู ุดุฎุต ูุน ููุตุจ (ูุฏูุฑุ ุฑุฆูุณุ ูุฒูุฑุ ุฅูุฎ)ุ ุชุญูู ููุฑุงู ูู ุตุญุฉ ุงูุงุณู!\n\n"
                "ุงุณุชุฎุฏู ูุชุงุฆุฌ ุงูุจุญุซ ููุชุญูู ูู:\n"
                "   - ูู ุงูุงุณู ุงููุฐููุฑ ูู ุงูุดุฎุต ุงูุตุญูุญ ุงูุฐู ูุดุบู ูุฐุง ุงูููุตุจุ\n"
                "   - ุฅุฐุง ูุงู ุงูุงุณู ุฎุงุทุฆุงูุ ุงุณุชุจุฏูู ุจุงูุงุณู ุงูุตุญูุญ ูู ูุชุงุฆุฌ ุงูุจุญุซ\n\n"
                "ุฃูุซูุฉ:\n"
                "   โ 'ุงููุฏูุฑ ุงูุนุงู ููููุงุ ุงุณูุงู ุจุฏุฑุงู' โ โ 'ุงููุฏูุฑ ุงูุนุงู ููููุงุ ูุญูุฏ ุจู ุนุจุฏุฑุจู ุงููุงูู'\n"
                "   (ุฅุฐุง ุฃุธูุฑุช ูุชุงุฆุฌ ุงูุจุญุซ ุฃู ุงููุฏูุฑ ุงูุตุญูุญ ูู ูุญูุฏ ุจู ุนุจุฏุฑุจู ุงููุงูู)\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "4. **ุงูุชุญูู ูู ูุนูููุงุช ุฃุฎุฑู:**\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "   - ุชุญูู ูู ุตุญุฉ ุงููุนูููุงุช ุงูุชุงุฑูุฎูุฉ (ุชูุงุฑูุฎุ ุฃุญุฏุงุซ)\n"
                "   - ุชุญูู ูู ุตุญุฉ ุงูุฃุฑูุงู ูุงูุฅุญุตุงุฆูุงุช ุฅุฐุง ูุงูุช ูุงุถุญุฉ ุงูุฎุทุฃ\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "5. **ุงูุชุตุญูุญ ุงููุบูู (ุซุงููู):**\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "   - ุชุตุญูุญ ุงูุฃุฎุทุงุก ุงูุฅููุงุฆูุฉ\n"
                "   - ุชุตุญูุญ ุงูุฃุฎุทุงุก ุงููุญููุฉ\n\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "6. **ููุงุนุฏ ุงูุฅุฎุฑุงุฌ (ููู ุฌุฏุงู):**\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "   โ ุฃุนุฏ ููุท ุงููุต ุงููุตุญุญ ุจุฏูู ุฃู ุฅุถุงูุงุช\n"
                "   โ ูุง ุชูุชุจ 'ุงููุต ุงููุตุญุญ:' ุฃู ุฃู ุนูุงููู\n"
                "   โ ูุง ุชุถู ุดุฑูุญุงุช ุฃู ุชุนูููุงุช\n"
                "   โ ุญุงูุธ ุนูู ุฃุณููุจ ุงููุต ุงูุฃุตูู\n"
                "   โ ูุง ุชุถู ูุนูููุงุช ุฌุฏูุฏุฉ\n\n"
                "๐ด ุชุฐููุฑ ุฃุฎูุฑ: ุงุณุชุฎุฏู ูุชุงุฆุฌ ุงูุจุญุซ ุงูููุฏูุฉ ููุชุญูู ูู ุตุญุฉ ุงููุนูููุงุช!"
            ),
        },
        {
            "role": "user",
            "content": (
                f"ุงููุต ุงููุทููุจ ุงูุชุญูู ููู ูุชุตุญูุญู:\n{text_to_check}\n\n"
                f"โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                f"ูุชุงุฆุฌ ุงูุจุญุซ ูู ุฌูุฌู ููุชุญูู ูู ุตุญุฉ ุงููุนูููุงุช:\n"
                f"โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
                f"{search_results}\n\n"
                f"โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                f"ุงุณุชุฎุฏู ูุชุงุฆุฌ ุงูุจุญุซ ุฃุนูุงู ููุชุญูู ูู ุตุญุฉ ุงููุนูููุงุช ูุชุตุญูุญูุง.\n"
                f"ุฃุนุฏ ุงููุต ุงููุตุญุญ ููุท ุจุฏูู ุฃู ุดุฑูุญุงุช."
            ),
        },
    ]

    result_text = ""
    if hasattr(client, "responses"):
        response = client.responses.create(model=model, input=messages)
        result_text = response.output_text.strip()
    else:
        chat_client = getattr(client, "chat", None)
        if chat_client and hasattr(chat_client, "completions"):
            response = chat_client.completions.create(model=model, messages=messages)
            if response.choices:
                result_text = response.choices[0].message.content.strip()
        else:
            raise RuntimeError("OpenAI client does not support responses or chat completions API.")

    return result_text


def generate_review(
    *,
    news_text: str,
    guideline_chunks: Iterable[RetrievedChunk],
    example_chunks: Iterable[RetrievedChunk],
    model: str = DEFAULT_COMPLETION_MODEL,
) -> str:
    # First, check if there are any ##text## markers and correct them
    pattern = r'##(.+?)##'
    matches = re.findall(pattern, news_text, re.DOTALL)

    if matches:
        # Process each match and replace in the original text
        processed_text = news_text
        for match in matches:
            corrected = check_and_correct_text_between_hashtags(
                text=f"##{match}##",
                model=model,
                full_context=news_text  # Pass full context for better fact-checking
            )
            # Replace the ##original## with the corrected text (without ##)
            processed_text = processed_text.replace(f"##{match}##", corrected, 1)
        news_text = processed_text

    client = _get_openai_client()
    messages = build_review_prompt(news_text, guideline_chunks, example_chunks)

    result_text = ""
    if hasattr(client, "responses"):
        response = client.responses.create(model=model, input=messages)
        result_text = response.output_text.strip()
    else:
        chat_client = getattr(client, "chat", None)
        if chat_client and hasattr(chat_client, "completions"):
            response = chat_client.completions.create(model=model, messages=messages)
            if response.choices:
                result_text = response.choices[0].message.content.strip()
        else:
            raise RuntimeError("OpenAI client does not support responses or chat completions API.")

    # Check if the model rejected the text as inappropriate or random
    if result_text.startswith("ERROR:") or "ุบูุฑ ููุงุณุจ" in result_text or "ุบูุฑ ุตุงูุญ" in result_text:
        error_msg = result_text.replace("ERROR:", "").strip()
        if not error_msg:
            error_msg = "ุงููุต ุงูููุฏู ุบูุฑ ููุงุณุจ ุฃู ุบูุฑ ุตุงูุญ ูููุนุงูุฌุฉ. ูุฑุฌู ุชูุฏูู ุฎุจุฑ ุตุญูุญ."
        raise ValueError(error_msg)

    # Final pass: ensure any remaining honorifics are processed
    # This catches any honorifics the model might have missed
    final_text = _preprocess_honorifics(result_text)

    # Post-process to ensure proper paragraph separation
    final_text = _split_into_paragraphs(final_text)

    return final_text


# =============================================================================
# DOCUMENT RETRIEVAL FUNCTIONS
# =============================================================================

def list_documents(
    document_type: DocumentChunk.DocumentType | None = None,
) -> dict:
    """
    List all uploaded documents grouped by title.

    Args:
        document_type: Optional filter by document type (guideline/example)

    Returns:
        Dictionary with document summaries
    """
    queryset = DocumentChunk.objects.all()
    if document_type:
        queryset = queryset.filter(document_type=document_type)

    # Group by title and document_type
    from django.db.models import Count, Min

    documents = (
        queryset
        .values('title', 'source_name', 'document_type')
        .annotate(
            total_chunks=Count('id'),
            created_at=Min('created_at')
        )
        .order_by('-created_at')
    )

    return {
        "total_documents": len(documents),
        "total_chunks": queryset.count(),
        "documents": list(documents),
    }


def get_document_detail(
    title: str,
    document_type: DocumentChunk.DocumentType | None = None,
) -> dict | None:
    """
    Get detailed information about a specific document including all chunks.

    Args:
        title: The document title
        document_type: Optional filter by document type

    Returns:
        Dictionary with document details and chunks, or None if not found
    """
    queryset = DocumentChunk.objects.filter(title=title)
    if document_type:
        queryset = queryset.filter(document_type=document_type)

    chunks = list(queryset.order_by('order'))
    if not chunks:
        return None

    first_chunk = chunks[0]
    return {
        "title": first_chunk.title,
        "source_name": first_chunk.source_name,
        "document_type": first_chunk.document_type,
        "total_chunks": len(chunks),
        "created_at": first_chunk.created_at,
        "chunks": [
            {
                "id": chunk.id,
                "document_type": chunk.document_type,
                "title": chunk.title,
                "source_name": chunk.source_name,
                "order": chunk.order,
                "text": chunk.text,
                "metadata": chunk.metadata,
                "created_at": chunk.created_at,
            }
            for chunk in chunks
        ],
    }


def delete_document(
    title: str,
    document_type: DocumentChunk.DocumentType | None = None,
) -> int:
    """
    Delete a document and all its chunks.

    Args:
        title: The document title
        document_type: Optional filter by document type

    Returns:
        Number of chunks deleted
    """
    queryset = DocumentChunk.objects.filter(title=title)
    if document_type:
        queryset = queryset.filter(document_type=document_type)

    count = queryset.count()
    queryset.delete()
    return count


def list_batches(
    document_type: str | None = None,
    status: str | None = None,
) -> List[dict]:
    """
    List all batch uploads with optional filters.

    Args:
        document_type: Optional filter by document type
        status: Optional filter by status

    Returns:
        List of batch records
    """
    queryset = FileUploadBatch.objects.all()
    if document_type:
        queryset = queryset.filter(document_type=document_type)
    if status:
        queryset = queryset.filter(status=status)

    return [
        {
            "batch_id": str(batch.id),
            "document_type": batch.document_type,
            "status": batch.status,
            "total_files": batch.total_files,
            "processed_files": batch.processed_files,
            "total_chunks_created": batch.total_chunks_created,
            "error_message": batch.error_message,
            "created_at": batch.created_at,
            "updated_at": batch.updated_at,
        }
        for batch in queryset
    ]


def get_batch_files(batch_id: str) -> List[dict]:
    """
    Get all files in a batch upload.

    Args:
        batch_id: UUID of the batch

    Returns:
        List of file records
    """
    try:
        batch = FileUploadBatch.objects.get(id=batch_id)
    except FileUploadBatch.DoesNotExist:
        raise ValueError(f"Batch {batch_id} not found")

    return [
        {
            "id": f.id,
            "filename": f.filename,
            "title": f.title,
            "file_size": f.file_size,
            "status": f.status,
            "chunks_created": f.chunks_created,
            "error_message": f.error_message,
            "created_at": f.created_at,
        }
        for f in batch.files.all()
    ]


def get_statistics() -> dict:
    """
    Get overall statistics about uploaded documents.

    Returns:
        Dictionary with statistics
    """
    total_guidelines = DocumentChunk.objects.filter(
        document_type=DocumentChunk.DocumentType.GUIDELINE
    ).count()
    total_examples = DocumentChunk.objects.filter(
        document_type=DocumentChunk.DocumentType.EXAMPLE
    ).count()

    # Count unique documents by title
    guideline_docs = (
        DocumentChunk.objects
        .filter(document_type=DocumentChunk.DocumentType.GUIDELINE)
        .values('title')
        .distinct()
        .count()
    )
    example_docs = (
        DocumentChunk.objects
        .filter(document_type=DocumentChunk.DocumentType.EXAMPLE)
        .values('title')
        .distinct()
        .count()
    )

    return {
        "guidelines": {
            "total_documents": guideline_docs,
            "total_chunks": total_guidelines,
        },
        "examples": {
            "total_documents": example_docs,
            "total_chunks": total_examples,
        },
        "total_documents": guideline_docs + example_docs,
        "total_chunks": total_guidelines + total_examples,
    }

